{"title":"Exploring the Relationship Between Income and Living Location Preference","markdown":{"yaml":{"title":"Exploring the Relationship Between Income and Living Location Preference","subtitle":"A Comparative Analysis of Linear and Non-Linear Regression Models","author":"Heba Nusair","date":"2023-11-10","categories":["news","code","analysis"],"image":"images.jfif"},"headingText":"**Introduction**","containsRefs":false,"markdown":"\n\n\nLiving in Roanoke: Does Your Income Decide Your Address? We've dived into the world of Roanoke's remote workers to see how much their earnings influence where they live. Using linear regression, we've connected the dots between income and neighborhood choices in this vibrant metropolitan area. Check out our eye-opening findings in the figure below! (See the figure).\n\n![The urban areas classification in Roanoke Metropolitan Area produced by the author.](Urban_NonUrban_Rural.jpg){fig-align=\"center\" width=\"503\"}\n\n#### **The Study at a Glance**\n\nOur dataset included responses from individuals, detailing their income levels and their preferred living areas, ranging from the bustling city center to the tranquil rural landscapes. We analyzed responses detailing income levels and preferred living areas, from busy city centers to peaceful rural settings. Our unique \"relocating index\" helped us turn these preferences into measurable data. So again, the variables used are processed as the following:\n\n-   Transforming income into a continuous scale, assigning monetary values to income brackets.\n\n-   Converting living area preferences into a single, ordinal dependent variable 'Living Location Preference: *moving from urban to rural index*'.\n\n#### Insights from Linear Regression Analysis\n\nEmploying linear regression to model the relationship between the two variables: income & Relocating index.\n\n```{python}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocationPrefrences.xlsx')\n\n# Handle NaN values\ndata.dropna(subset=['City_center', 'Urban_area', 'Suburban_area', 'Rural_area', 'Monthly_income'], inplace=True)\n\n# Convert the Location preferences into a single ordinal dependent variable\narea_to_number = {'City_center': 1, 'Urban_area': 2, 'Suburban_area': 3, 'Rural_area': 4}\ndata['living_Location_preference'] = data[['City_center', 'Urban_area', 'Suburban_area', 'Rural_area']].idxmin(axis=1).map(area_to_number)\n\n# Convert income to a continuous scale based on the provided income brackets\nincome_mapping = {1.0: 625, 2.0: 2292, 3.0: 5000, 4.0: 6666}\ndata['continuous_income'] = data['Monthly_income'].map(income_mapping)\n\n# Scale the income feature\nscaler = StandardScaler()\ndata['scaled_income'] = scaler.fit_transform(data[['continuous_income']])\n\n# Prepare the features and target variable for modeling\nX = data[['scaled_income']]\ny = data['living_Location_preference']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred = model.predict(X_test)\n\n# Evaluate the model's performance\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Output the performance metrics\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\n\n# Debugging the sizes of arrays\nprint(\"Sizes of arrays for plotting:\")\nprint(\"X_test['scaled_income']: \", len(X_test['scaled_income']))\nprint(\"y_test: \", len(y_test))\nprint(\"y_pred: \", len(y_pred))\n\n# Plotting\nplt.scatter(X_test['scaled_income'].values, y_test.values, color='black', label='Actual Data')\nplt.scatter(X_test['scaled_income'].values, y_pred, color='red', label='Predicted Data', alpha=0.5)\n\n# Optionally, create a more continuous line for predictions\nsorted_order = np.argsort(X_test['scaled_income'].values)\nplt.plot(X_test['scaled_income'].values[sorted_order], y_pred[sorted_order], color='blue', linewidth=2, label='Regression Line')\n\nplt.xlabel('Monthly income')\nplt.ylabel('Living Location Preference:Relocating index_From urban to rural')\nplt.title('Income vs Living Location Preference Linear Regression')\nplt.legend()\nplt.show()\n\n\n```\n\nIn this plot, the actual data points (black dots) showed significant deviation from the blue regression line (the model's predictions). The red dots, representing the model's predicted values, also varied widely from many actual data points, indicating a mismatch between the model's predictions and the real data.\n\n#### **Unveiling the Linear Regression Insights for WFH Workers**\n\nOur linear regression model yielded the following insights:\n\n-   **Mean Squared Error (MSE)**: The model showed an MSE of 1.2658068009077692. This number, though not extremely high, indicates some discrepancies between the model's predictions and the actual data.\n\n-   **R-squared Value**: We obtained an R-squared value of 0.006851215790502296. This low value suggests that our model might not be capturing the complete picture, especially in the context of WFH employees.\n\n#### Transitioning to Non-Linear Models\n\nThe visual and numerical analysis led us to consider that the relationship between income and living area preferences might not be linear. This prompted a shift towards exploring non-linear patterns, **We Chose a** Multinomial Logistic Regression!!!! for these key reasons:\n\n1.  **Appropriate for Ordinal Data**: Our data on living location preferences is ordinal (ranging from city centers to rural areas). Ordinal regression accurately handles such data, unlike linear regression.\n\n2.  **Captures Non-Linear Patterns**: This model is better suited to reveal non-linear relationships between income and living location preferences, which our initial analysis suggested.\n\n3.  **Enhanced Predictive Accuracy**: Ordinal regression aligns more closely with our real-world data, potentially offering improved accuracy in predictions.\n\n#### **Implementing** Multinomial Logistic Regression Analysis\n\nIn this analysis. the location preferences into a single variable suggests that the resulting data is ordinal in nature. Here's why:\n\n-   The values assigned (1 for 'City_center', 2 for 'Urban_area', 3 for 'Suburban_area', and 4 for 'Rural_area') imply an order or ranking.\n\n-   The order seems to represent a gradient from the most urbanized area ('City_center') to the least ('Rural_area').\n\nGiven this structure, the variable 'preference rank' would be more appropriate for ordinal regression analysis since it reflects a clear order or hierarchy in the data.\n\n```{python}\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocation_GradientBoostingRegressor.xlsx')  \n# Update the path to your file\n\n# Combine the area preferences into a single ordinal variable\ndef get_preference_rank(row):\n    if row['City_center'] == 1:\n        return 1\n    elif row['Urban_area'] == 1:\n        return 2\n    elif row['Suburban_area'] == 1:\n        return 3\n    elif row['Rural_area'] == 1:\n        return 4\n\ndata['living_area_preference'] = data.apply(get_preference_rank, axis=1)\n\n# Prepare the features and the target variable\nX = data[['Monthly_income', 'Education_Level', 'House_owner_or_renter', 'number of employees in household']]\ny = data['living_area_preference']\n\n# Add a constant to the model (intercept)\nX = sm.add_constant(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the ordinal regression model\nmodel = sm.MNLogit(y_train, X_train)\nresult = model.fit()\n\n# Output the model summary\nprint(result.summary())\n\n\n\n```\n\n#### The Multinomial Logistic Regression analysis revealed some interesting insights about the relationship between various factors and living area preferences:\n\n1.  **Model Convergence and Fit**: The model successfully converged after 5 iterations, indicating a reliable fit to the data. The Pseudo R-squared value of 0.03553, while modest, suggests that our model has some explanatory power, though other unaccounted factors might also play a significant role.\n\n2.  **Significant Predictors**:\n\n    -   **Monthly Income**: This was a significant predictor across all living area preferences (2, 3, and 4). The negative coefficients (-0.6509, -0.7957, and -0.5330) indicate that as monthly income increases, the likelihood of preferring urban (2) or suburban (3) areas over rural (4) areas decreases.\n\n    -   **House Ownership Status**: This variable also showed significance in influencing living area preference, with negative coefficients suggesting that those who own houses or are renters are less likely to prefer urban or suburban areas compared to rural ones.\n\n3.  **Other Factors**:\n\n    -   **Education Level**: While the coefficients were positive, suggesting a higher likelihood of preferring urban or suburban areas with increased education level, the significance was marginal.\n\n    -   **Number of Employees in Household**: This factor did not show a strong influence on living area preference, as indicated by the higher p-values.\n\n4.  **Coefficient Interpretation**: The coefficients for each predictor vary for different living area preferences, reflecting the complex nature of these relationships. For instance, the impact of monthly income is more pronounced in preferring suburban areas (living_area_preference=3) than in urban or rural areas.\n\nIn conclusion, our Multinomial Logistic Regression model sheds light on how factors like income and house ownership status significantly influence living area preferences among WFH workers. The nuanced differences in coefficients across different living areas underscore the complexity of these relationships.\n","srcMarkdownNoYaml":"\n\n#### **Introduction**\n\nLiving in Roanoke: Does Your Income Decide Your Address? We've dived into the world of Roanoke's remote workers to see how much their earnings influence where they live. Using linear regression, we've connected the dots between income and neighborhood choices in this vibrant metropolitan area. Check out our eye-opening findings in the figure below! (See the figure).\n\n![The urban areas classification in Roanoke Metropolitan Area produced by the author.](Urban_NonUrban_Rural.jpg){fig-align=\"center\" width=\"503\"}\n\n#### **The Study at a Glance**\n\nOur dataset included responses from individuals, detailing their income levels and their preferred living areas, ranging from the bustling city center to the tranquil rural landscapes. We analyzed responses detailing income levels and preferred living areas, from busy city centers to peaceful rural settings. Our unique \"relocating index\" helped us turn these preferences into measurable data. So again, the variables used are processed as the following:\n\n-   Transforming income into a continuous scale, assigning monetary values to income brackets.\n\n-   Converting living area preferences into a single, ordinal dependent variable 'Living Location Preference: *moving from urban to rural index*'.\n\n#### Insights from Linear Regression Analysis\n\nEmploying linear regression to model the relationship between the two variables: income & Relocating index.\n\n```{python}\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocationPrefrences.xlsx')\n\n# Handle NaN values\ndata.dropna(subset=['City_center', 'Urban_area', 'Suburban_area', 'Rural_area', 'Monthly_income'], inplace=True)\n\n# Convert the Location preferences into a single ordinal dependent variable\narea_to_number = {'City_center': 1, 'Urban_area': 2, 'Suburban_area': 3, 'Rural_area': 4}\ndata['living_Location_preference'] = data[['City_center', 'Urban_area', 'Suburban_area', 'Rural_area']].idxmin(axis=1).map(area_to_number)\n\n# Convert income to a continuous scale based on the provided income brackets\nincome_mapping = {1.0: 625, 2.0: 2292, 3.0: 5000, 4.0: 6666}\ndata['continuous_income'] = data['Monthly_income'].map(income_mapping)\n\n# Scale the income feature\nscaler = StandardScaler()\ndata['scaled_income'] = scaler.fit_transform(data[['continuous_income']])\n\n# Prepare the features and target variable for modeling\nX = data[['scaled_income']]\ny = data['living_Location_preference']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred = model.predict(X_test)\n\n# Evaluate the model's performance\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Output the performance metrics\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\n\n# Debugging the sizes of arrays\nprint(\"Sizes of arrays for plotting:\")\nprint(\"X_test['scaled_income']: \", len(X_test['scaled_income']))\nprint(\"y_test: \", len(y_test))\nprint(\"y_pred: \", len(y_pred))\n\n# Plotting\nplt.scatter(X_test['scaled_income'].values, y_test.values, color='black', label='Actual Data')\nplt.scatter(X_test['scaled_income'].values, y_pred, color='red', label='Predicted Data', alpha=0.5)\n\n# Optionally, create a more continuous line for predictions\nsorted_order = np.argsort(X_test['scaled_income'].values)\nplt.plot(X_test['scaled_income'].values[sorted_order], y_pred[sorted_order], color='blue', linewidth=2, label='Regression Line')\n\nplt.xlabel('Monthly income')\nplt.ylabel('Living Location Preference:Relocating index_From urban to rural')\nplt.title('Income vs Living Location Preference Linear Regression')\nplt.legend()\nplt.show()\n\n\n```\n\nIn this plot, the actual data points (black dots) showed significant deviation from the blue regression line (the model's predictions). The red dots, representing the model's predicted values, also varied widely from many actual data points, indicating a mismatch between the model's predictions and the real data.\n\n#### **Unveiling the Linear Regression Insights for WFH Workers**\n\nOur linear regression model yielded the following insights:\n\n-   **Mean Squared Error (MSE)**: The model showed an MSE of 1.2658068009077692. This number, though not extremely high, indicates some discrepancies between the model's predictions and the actual data.\n\n-   **R-squared Value**: We obtained an R-squared value of 0.006851215790502296. This low value suggests that our model might not be capturing the complete picture, especially in the context of WFH employees.\n\n#### Transitioning to Non-Linear Models\n\nThe visual and numerical analysis led us to consider that the relationship between income and living area preferences might not be linear. This prompted a shift towards exploring non-linear patterns, **We Chose a** Multinomial Logistic Regression!!!! for these key reasons:\n\n1.  **Appropriate for Ordinal Data**: Our data on living location preferences is ordinal (ranging from city centers to rural areas). Ordinal regression accurately handles such data, unlike linear regression.\n\n2.  **Captures Non-Linear Patterns**: This model is better suited to reveal non-linear relationships between income and living location preferences, which our initial analysis suggested.\n\n3.  **Enhanced Predictive Accuracy**: Ordinal regression aligns more closely with our real-world data, potentially offering improved accuracy in predictions.\n\n#### **Implementing** Multinomial Logistic Regression Analysis\n\nIn this analysis. the location preferences into a single variable suggests that the resulting data is ordinal in nature. Here's why:\n\n-   The values assigned (1 for 'City_center', 2 for 'Urban_area', 3 for 'Suburban_area', and 4 for 'Rural_area') imply an order or ranking.\n\n-   The order seems to represent a gradient from the most urbanized area ('City_center') to the least ('Rural_area').\n\nGiven this structure, the variable 'preference rank' would be more appropriate for ordinal regression analysis since it reflects a clear order or hierarchy in the data.\n\n```{python}\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocation_GradientBoostingRegressor.xlsx')  \n# Update the path to your file\n\n# Combine the area preferences into a single ordinal variable\ndef get_preference_rank(row):\n    if row['City_center'] == 1:\n        return 1\n    elif row['Urban_area'] == 1:\n        return 2\n    elif row['Suburban_area'] == 1:\n        return 3\n    elif row['Rural_area'] == 1:\n        return 4\n\ndata['living_area_preference'] = data.apply(get_preference_rank, axis=1)\n\n# Prepare the features and the target variable\nX = data[['Monthly_income', 'Education_Level', 'House_owner_or_renter', 'number of employees in household']]\ny = data['living_area_preference']\n\n# Add a constant to the model (intercept)\nX = sm.add_constant(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the ordinal regression model\nmodel = sm.MNLogit(y_train, X_train)\nresult = model.fit()\n\n# Output the model summary\nprint(result.summary())\n\n\n\n```\n\n#### The Multinomial Logistic Regression analysis revealed some interesting insights about the relationship between various factors and living area preferences:\n\n1.  **Model Convergence and Fit**: The model successfully converged after 5 iterations, indicating a reliable fit to the data. The Pseudo R-squared value of 0.03553, while modest, suggests that our model has some explanatory power, though other unaccounted factors might also play a significant role.\n\n2.  **Significant Predictors**:\n\n    -   **Monthly Income**: This was a significant predictor across all living area preferences (2, 3, and 4). The negative coefficients (-0.6509, -0.7957, and -0.5330) indicate that as monthly income increases, the likelihood of preferring urban (2) or suburban (3) areas over rural (4) areas decreases.\n\n    -   **House Ownership Status**: This variable also showed significance in influencing living area preference, with negative coefficients suggesting that those who own houses or are renters are less likely to prefer urban or suburban areas compared to rural ones.\n\n3.  **Other Factors**:\n\n    -   **Education Level**: While the coefficients were positive, suggesting a higher likelihood of preferring urban or suburban areas with increased education level, the significance was marginal.\n\n    -   **Number of Employees in Household**: This factor did not show a strong influence on living area preference, as indicated by the higher p-values.\n\n4.  **Coefficient Interpretation**: The coefficients for each predictor vary for different living area preferences, reflecting the complex nature of these relationships. For instance, the impact of monthly income is more pronounced in preferring suburban areas (living_area_preference=3) than in urban or rural areas.\n\nIn conclusion, our Multinomial Logistic Regression model sheds light on how factors like income and house ownership status significantly influence living area preferences among WFH workers. The nuanced differences in coefficients across different living areas underscore the complexity of these relationships.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","page-layout":"full","theme":{"light":["flatly","light.scss"],"dark":["darkly","dark.scss"]},"grid":{"sidebar-width":"150px","body-width":"1800px","margin-width":"250px"},"title-block-banner":true,"title":"Exploring the Relationship Between Income and Living Location Preference","subtitle":"A Comparative Analysis of Linear and Non-Linear Regression Models","author":"Heba Nusair","date":"2023-11-10","categories":["news","code","analysis"],"image":"images.jfif"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}