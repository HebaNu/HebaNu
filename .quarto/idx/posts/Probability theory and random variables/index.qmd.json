{"title":"Probability theory and random variables","markdown":{"yaml":{"title":"Probability theory and random variables","author":"Heba Nusair","date":"2023-11-06","categories":["news","code","analysis"],"image":"Capture.JPG","code-viewfold":true},"headingText":"Step 1: Load the dataset","containsRefs":false,"markdown":"\n\n***Categorical Naive Bayes***\n\nThis project requires Python 3.7 or above:\n\n```{python}\n\nimport sys\n\nassert sys.version_info >= (3, 7)\n```\n\nFor the analysis I a planning, Python libraries like Pandas, Matplotlib, and Scikit-learn will be handy. Here's a high-level step-by-step guide to get you started: First I need to make Exploratory Data Analysis (EDA):\n\n```{python}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\n\ndf = pd.read_excel('CategoricalNB.xlsx')\n\n# Print the column names to check for any discrepancies\nprint(df.columns)\n\n# Step 2: Encode the 'Industry sector' using one-hot encoding\n# Notice the space before 'Industry sector' in the column name\nencoder = OneHotEncoder(sparse=False)\nX = encoder.fit_transform(df[[' Industry sector']])\n\n# The 'Working Method' feature is your target variable\ny = df['Working Method']\n\n# Step 3: Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 4: Train the Multinomial Naive Bayes model\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)\n\n# Step 5: Make predictions and evaluate the model\ny_pred = model.predict(X_test)\n\n# Use the classification report to handle divisions by zero\nprint(classification_report(y_test, y_pred, zero_division=0))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n\n```\n\nThe output indicates that the code has successfully run and produced a classification report, but it shows that the Multinomial Naive Bayes classifier is not performing well for some classes (especially class 4). The FutureWarning is just to inform you about a future change in the scikit-learn library and doesn't impact the current execution of your code. It suggests that in the future version, the sparse parameter in OneHotEncoder will be removed and recommends using sparse_output instead. Since it's just a warning about future changes, you can ignore it for now.\n\nThe classification report shows the following:\n\nClass 1 has a precision of 0.50 and recall of 0.29. Class 2 has a precision of 0.47 and recall of 0.91, which is quite good. Class 3 has a precision of 0.45 and recall of 0.13, indicating the model struggles to correctly identify this class. Class 4 has both precision and recall of 0.00, which means the model fails to identify any samples of this class correctly. This poor performance for some classes may be due to class imbalance, insufficient features, or the model's inability to capture the complexities of the dataset.\n\nHere are a few recommendations to improve the model's performance:\n\nAddress Class Imbalance: Use techniques like SMOTE, ADASYN, or simply oversampling the minority class to balance the dataset. Feature Engineering: Add more features that could help the classifier distinguish between classes. Hyperparameter Tuning: Experiment with different hyperparameters for the MultinomialNB classifier. Try Different Models: Since Naive Bayes assumes feature independence and your features might be correlated, other models like Random Forest or Gradient Boosting might perform better. Evaluation Metrics: Use other evaluation metrics like AUC-ROC curve, especially when dealing with imbalanced classes. \n\n\n","srcMarkdownNoYaml":"\n\n***Categorical Naive Bayes***\n\nThis project requires Python 3.7 or above:\n\n```{python}\n\nimport sys\n\nassert sys.version_info >= (3, 7)\n```\n\nFor the analysis I a planning, Python libraries like Pandas, Matplotlib, and Scikit-learn will be handy. Here's a high-level step-by-step guide to get you started: First I need to make Exploratory Data Analysis (EDA):\n\n```{python}\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Step 1: Load the dataset\ndf = pd.read_excel('CategoricalNB.xlsx')\n\n# Print the column names to check for any discrepancies\nprint(df.columns)\n\n# Step 2: Encode the 'Industry sector' using one-hot encoding\n# Notice the space before 'Industry sector' in the column name\nencoder = OneHotEncoder(sparse=False)\nX = encoder.fit_transform(df[[' Industry sector']])\n\n# The 'Working Method' feature is your target variable\ny = df['Working Method']\n\n# Step 3: Split the dataset into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Step 4: Train the Multinomial Naive Bayes model\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)\n\n# Step 5: Make predictions and evaluate the model\ny_pred = model.predict(X_test)\n\n# Use the classification report to handle divisions by zero\nprint(classification_report(y_test, y_pred, zero_division=0))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n\n```\n\nThe output indicates that the code has successfully run and produced a classification report, but it shows that the Multinomial Naive Bayes classifier is not performing well for some classes (especially class 4). The FutureWarning is just to inform you about a future change in the scikit-learn library and doesn't impact the current execution of your code. It suggests that in the future version, the sparse parameter in OneHotEncoder will be removed and recommends using sparse_output instead. Since it's just a warning about future changes, you can ignore it for now.\n\nThe classification report shows the following:\n\nClass 1 has a precision of 0.50 and recall of 0.29. Class 2 has a precision of 0.47 and recall of 0.91, which is quite good. Class 3 has a precision of 0.45 and recall of 0.13, indicating the model struggles to correctly identify this class. Class 4 has both precision and recall of 0.00, which means the model fails to identify any samples of this class correctly. This poor performance for some classes may be due to class imbalance, insufficient features, or the model's inability to capture the complexities of the dataset.\n\nHere are a few recommendations to improve the model's performance:\n\nAddress Class Imbalance: Use techniques like SMOTE, ADASYN, or simply oversampling the minority class to balance the dataset. Feature Engineering: Add more features that could help the classifier distinguish between classes. Hyperparameter Tuning: Experiment with different hyperparameters for the MultinomialNB classifier. Try Different Models: Since Naive Bayes assumes feature independence and your features might be correlated, other models like Random Forest or Gradient Boosting might perform better. Evaluation Metrics: Use other evaluation metrics like AUC-ROC curve, especially when dealing with imbalanced classes. \n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","editor":"visual","grid":{"sidebar-width":"250px","body-width":"600px","margin-width":"450px","gutter-width":"1.5em"},"theme":"Darkly","title-block-banner":true,"title":"Probability theory and random variables","author":"Heba Nusair","date":"2023-11-06","categories":["news","code","analysis"],"image":"Capture.JPG","code-viewfold":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}