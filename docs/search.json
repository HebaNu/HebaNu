[
  {
    "objectID": "Research Overview.html",
    "href": "Research Overview.html",
    "title": "Research Overview",
    "section": "",
    "text": "Work From Home and Cityscape\nExperience the transformative shift in work dynamics worldwide. Fueled by factors like flexibility and propelled by the seismic impact of the Covid-19 pandemic, remote work, particularly Working From Home (WFH), has become a prevailing trend. This change in work culture is not merely a temporary response but a catalyst for a prolonged paradigm shift in workplaces globally.\nAs the emphasis on proximity to the workplace diminishes, individuals are opting for relocations to suburban areas, seeking affordable housing options without compromising living standards. This evolution in the work landscape intertwines with broader implications for cities—altering socioeconomic structures, reshaping urban landscapes, and influencing environmental dynamics.\nJoin us on this exploration of a dynamic era where work and living spaces converge, uncovering the profound effects of this transformative journey on cities, society, and the natural environment. Welcome to a new era in the world of work and living.\n\n\nDatasets Used\nSurvey Overview: The datasets for this survey focus on examining the profound impact of remote work on urban expansion and residential choices. Participants across various occupations have provided valuable insights through a comprehensive questionnaire. This data delves into working methods—remote or in-person—and their influence on housing location preferences. Additionally, it explores behavioral patterns relative to one’s working mode, shedding light on human-environment interactions and spatial dynamics.\nImportant Note: The datasets used on these posts are modified and synthesized, so they should be used solely for educational purposes and to demonstrate data analysis techniques. Please refrain from using this data for any genuine applications."
  },
  {
    "objectID": "posts/Probability theory and random variables/index.html",
    "href": "posts/Probability theory and random variables/index.html",
    "title": "Probability theory and random variables",
    "section": "",
    "text": "Why I used this kind of analysis?\n\n\nCode\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\n\n# Load the dataset\ndf = pd.read_csv('C:/Users/NUSAI/Desktop/Machine learning/HebaNu.github.io/HebaNu.github.io/HebaNu/posts/Probability theory and random variables/POST1.csv')\n\n# Replace values in column 'Work Method'\ndf['Work Method'] = df['Work Method'].replace(3, 2)\ndf['Work Method'] = df['Work Method'].replace(4, 1)\n\n# Drop rows where any cell is NaN in the 'Work Method' column\ndf = df.dropna(subset=['Work Method'])\n\n# One-hot encoding\nencoder = OneHotEncoder(sparse=False)\nX = encoder.fit_transform(df[[' industry sector']])  \n# Use the correct column name\n\n# Target variable\ny = df['Work Method']\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the Bernoulli Naive Bayes model\nmodel = BernoulliNB()\nmodel.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\ny_pred = model.predict(X_test)\n\n# Save the updated DataFrame back to CSV\n# Define the full path for the output file\noutput_path = 'C:/Users/NUSAI/Desktop/Machine learning/HebaNu.github.io/HebaNu.github.io/HebaNu/posts/Probability theory and random variables/updated_POST1.csv'\n\n# Create the directory if it does not exist\nos.makedirs(os.path.dirname(output_path), exist_ok=True)\ndf.to_csv(output_path, index=False)\n\n# Output the classification report and accuracy\nprint(classification_report(y_test, y_pred, zero_division=0))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n\n\n              precision    recall  f1-score   support\n\n         1.0       0.00      0.00      0.00        40\n         2.0       0.76      1.00      0.87       130\n\n    accuracy                           0.76       170\n   macro avg       0.38      0.50      0.43       170\nweighted avg       0.58      0.76      0.66       170\n\nAccuracy: 0.7647058823529411\n\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning:\n\n`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n\n\n\nThe results from your BernoulliNB model show that:\nThe model is predicting class 2.0 with high precision (76%) and recall (100%), which means for this class, it performs well both in terms of the accuracy of the positive predictions it makes (precision) and its ability to find all the positive instances (recall).\nFor class 1.0, however, the model does not predict any instances correctly, which suggests that either there’s an issue with the distribution of your classes (perhaps class 1.0 is underrepresented), or that the features do not provide enough information to distinguish class 1.0 from class 2.0. The overall accuracy of the model is 76.47%, which means that it correctly predicts the class for 76.47% of the test set.\nThe macro avg and weighted avg for precision, recall, and f1-score provide a summary of the effectiveness of the model across the classes. The low macro avg for precision and f1-score indicates that one of the classes does not perform well, which we already know is class 1.0.\nThe f1-score is a harmonic mean of precision and recall and is a useful metric when you have classes that are imbalanced. In your case, the f1-score for class 1.0 is 0.00, indicating poor performance for this class.\nTo create plots that visualize the performance of your BernoulliNB model, you would typically look at the confusion matrix, precision-recall, and possibly ROC curves. Below are examples of how you could generate each of these plots using matplotlib and scikit-learn:\n\nConfusion Matrix: Visualizes the correct and incorrect predictions compared to the actual values.\n\n\n\nCode\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming y_test and y_pred are already defined from your BernoulliNB model\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion Matrix for BernoulliNB Model')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\n\n\n\n\nROC Curve: Plots the true positive rate against the false positive rate.\n\n\nCode\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\n\n# Adjust y_test to have binary labels 0 and 1\ny_test_binary = y_test.replace({1: 0, 2: 1})\n\n# Get predicted probabilities for the positive class (e.g., class 2)\ny_pred_prob = model.predict_proba(X_test)[:, 1]  # Index 1 for the probability of class 2\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_prob)\n\n# Calculate the AUC (Area Under Curve)\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve\ndisp = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\ndisp.plot()\nplt.title('ROC Curve for BernoulliNB Model')\nplt.show()\n\n\n\n\n\nClassification Report: Presents precision, recall, f1-score for each class.\n\n\nCode\nfrom sklearn.metrics import classification_report\nimport pandas as pd\n\nreport = classification_report(y_test, y_pred, output_dict=True)\ndf_report = pd.DataFrame(report).transpose()\n\ndf_report.drop(['accuracy'], inplace=True)  # Drop accuracy as it's not a class-specific metric\ndf_report.plot(kind='bar', figsize=(10, 7))\nplt.title('Classification Report for BernoulliNB Model')\nplt.ylabel('Score')\nplt.show()\n\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n\n\n\nPlease note that in order to generate a ROC curve or Precision-Recall curve, you need the probability scores or decision function, not just the predicted labels. If y_pred contains only class labels, you would need to use the predict_proba or decision_function method of your classifier to obtain these scores.\nThese code snippets are intended to be run in your local Python environment, and you’ll need to ensure that y_test and y_pred are defined in your workspace after running your BernoulliNB model. If you encounter any issues with these plots or if you require further customization, feel free to ask for additional guidance."
  },
  {
    "objectID": "posts/Probability theory and random variables/index.html#naive-bayes-classifier-for-multivariate-bernoulli-models",
    "href": "posts/Probability theory and random variables/index.html#naive-bayes-classifier-for-multivariate-bernoulli-models",
    "title": "Probability theory and random variables",
    "section": "",
    "text": "Why I used this kind of analysis?\n\n\nCode\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\n\n# Load the dataset\ndf = pd.read_csv('C:/Users/NUSAI/Desktop/Machine learning/HebaNu.github.io/HebaNu.github.io/HebaNu/posts/Probability theory and random variables/POST1.csv')\n\n# Replace values in column 'Work Method'\ndf['Work Method'] = df['Work Method'].replace(3, 2)\ndf['Work Method'] = df['Work Method'].replace(4, 1)\n\n# Drop rows where any cell is NaN in the 'Work Method' column\ndf = df.dropna(subset=['Work Method'])\n\n# One-hot encoding\nencoder = OneHotEncoder(sparse=False)\nX = encoder.fit_transform(df[[' industry sector']])  \n# Use the correct column name\n\n# Target variable\ny = df['Work Method']\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the Bernoulli Naive Bayes model\nmodel = BernoulliNB()\nmodel.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\ny_pred = model.predict(X_test)\n\n# Save the updated DataFrame back to CSV\n# Define the full path for the output file\noutput_path = 'C:/Users/NUSAI/Desktop/Machine learning/HebaNu.github.io/HebaNu.github.io/HebaNu/posts/Probability theory and random variables/updated_POST1.csv'\n\n# Create the directory if it does not exist\nos.makedirs(os.path.dirname(output_path), exist_ok=True)\ndf.to_csv(output_path, index=False)\n\n# Output the classification report and accuracy\nprint(classification_report(y_test, y_pred, zero_division=0))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n\n\n              precision    recall  f1-score   support\n\n         1.0       0.00      0.00      0.00        40\n         2.0       0.76      1.00      0.87       130\n\n    accuracy                           0.76       170\n   macro avg       0.38      0.50      0.43       170\nweighted avg       0.58      0.76      0.66       170\n\nAccuracy: 0.7647058823529411\n\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning:\n\n`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n\n\n\nThe results from your BernoulliNB model show that:\nThe model is predicting class 2.0 with high precision (76%) and recall (100%), which means for this class, it performs well both in terms of the accuracy of the positive predictions it makes (precision) and its ability to find all the positive instances (recall).\nFor class 1.0, however, the model does not predict any instances correctly, which suggests that either there’s an issue with the distribution of your classes (perhaps class 1.0 is underrepresented), or that the features do not provide enough information to distinguish class 1.0 from class 2.0. The overall accuracy of the model is 76.47%, which means that it correctly predicts the class for 76.47% of the test set.\nThe macro avg and weighted avg for precision, recall, and f1-score provide a summary of the effectiveness of the model across the classes. The low macro avg for precision and f1-score indicates that one of the classes does not perform well, which we already know is class 1.0.\nThe f1-score is a harmonic mean of precision and recall and is a useful metric when you have classes that are imbalanced. In your case, the f1-score for class 1.0 is 0.00, indicating poor performance for this class.\nTo create plots that visualize the performance of your BernoulliNB model, you would typically look at the confusion matrix, precision-recall, and possibly ROC curves. Below are examples of how you could generate each of these plots using matplotlib and scikit-learn:\n\nConfusion Matrix: Visualizes the correct and incorrect predictions compared to the actual values.\n\n\n\nCode\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming y_test and y_pred are already defined from your BernoulliNB model\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion Matrix for BernoulliNB Model')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\n\n\n\n\nROC Curve: Plots the true positive rate against the false positive rate.\n\n\nCode\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\n\n# Adjust y_test to have binary labels 0 and 1\ny_test_binary = y_test.replace({1: 0, 2: 1})\n\n# Get predicted probabilities for the positive class (e.g., class 2)\ny_pred_prob = model.predict_proba(X_test)[:, 1]  # Index 1 for the probability of class 2\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_prob)\n\n# Calculate the AUC (Area Under Curve)\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve\ndisp = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\ndisp.plot()\nplt.title('ROC Curve for BernoulliNB Model')\nplt.show()\n\n\n\n\n\nClassification Report: Presents precision, recall, f1-score for each class.\n\n\nCode\nfrom sklearn.metrics import classification_report\nimport pandas as pd\n\nreport = classification_report(y_test, y_pred, output_dict=True)\ndf_report = pd.DataFrame(report).transpose()\n\ndf_report.drop(['accuracy'], inplace=True)  # Drop accuracy as it's not a class-specific metric\ndf_report.plot(kind='bar', figsize=(10, 7))\nplt.title('Classification Report for BernoulliNB Model')\nplt.ylabel('Score')\nplt.show()\n\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning:\n\nPrecision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n\n\n\n\n\n\nPlease note that in order to generate a ROC curve or Precision-Recall curve, you need the probability scores or decision function, not just the predicted labels. If y_pred contains only class labels, you would need to use the predict_proba or decision_function method of your classifier to obtain these scores.\nThese code snippets are intended to be run in your local Python environment, and you’ll need to ensure that y_test and y_pred are defined in your workspace after running your BernoulliNB model. If you encounter any issues with these plots or if you require further customization, feel free to ask for additional guidance."
  },
  {
    "objectID": "posts/Exploratory Data Analysis (EDA)/index.html",
    "href": "posts/Exploratory Data Analysis (EDA)/index.html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "# Load necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load your dataset without specifying encoding\ndata = pd.read_excel('CategoricalNB.xlsx')\n\n# Summary statistics for Industry sector\nindustry_stats = data[' Industry sector'].value_counts()\n\n# Summary statistics for Working Method\nmethod_stats = data['Working Method'].value_counts()\n\n# Plotting\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.countplot(data=data, x=' Industry sector')\nplt.title('Distribution of Industry Sectors')\n\nplt.subplot(1, 2, 2)\nsns.countplot(data=data, x='Working Method')\nplt.title('Distribution of Working Methods')\n\nplt.tight_layout()\nplt.show()\n\n# Display summary statistics\nprint(\"Summary statistics for Industry sector:\")\nprint(industry_stats)\n\nprint(\"\\nSummary statistics for Working Method:\")\nprint(method_stats)\n\n\n\n\nSummary statistics for Industry sector:\n5     90\n7     62\n9     55\n15    47\n4     42\n12    41\n13    40\n10    40\n8     37\n6     33\n3     29\n1     27\n19    25\n16    22\n18    21\n2     17\n11    16\n17    16\n14    16\n20    13\nName:  Industry sector, dtype: int64\n\nSummary statistics for Working Method:\n2    320\n3    173\n1    120\n4     76\nName: Working Method, dtype: int64\n\n\nStudy the relationship between nominal variables (Industry sector and Working Method)statistical analyses:\nChi-Square Test of Independence: The Chi-Square test can be used to determine whether there is an association (relationship) between two categorical variables. In your case, you can use it to test if there is a relationship between Industry sector and Working Method. The null hypothesis (H0) is that the two variables are independent, and the alternative hypothesis (Ha) is that there is a significant association between them.\n\n# Load necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency\n\n# Load your dataset without specifying encoding\ndata = pd.read_excel('CategoricalNB.xlsx')\n\n\nfrom scipy.stats import chi2_contingency\n\n# Summary statistics for Industry sector\nindustry_stats = data[' Industry sector'].value_counts()\n\n# Summary statistics for Working Method\nmethod_stats = data['Working Method'].value_counts()\n\n# Plotting\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nsns.countplot(data=data, x=' Industry sector')\nplt.title('Distribution of Industry Sectors')\n\nplt.subplot(1, 2, 2)\nsns.countplot(data=data, x='Working Method')\nplt.title('Distribution of Working Methods')\n\nplt.tight_layout()\nplt.show()\n\n# Perform Chi-Square test of independence\ncontingency_table = pd.crosstab(data[' Industry sector'], data['Working Method'])\nchi2, p, dof, expected = chi2_contingency(contingency_table)\n\n# Check the p-value\nif p &lt; 0.05:\n    print(\"There is a significant relationship between Industry sector and Working Method.\")\nelse:\n    print(\"There is no significant relationship between Industry sector and Working Method.\")\n\n# Display summary statistics\nprint(\"Summary statistics for Industry sector:\")\nprint(industry_stats)\n\nprint(\"\\nSummary statistics for Working Method:\")\nprint(method_stats)\n\n\n\n\nThere is a significant relationship between Industry sector and Working Method.\nSummary statistics for Industry sector:\n5     90\n7     62\n9     55\n15    47\n4     42\n12    41\n13    40\n10    40\n8     37\n6     33\n3     29\n1     27\n19    25\n16    22\n18    21\n2     17\n11    16\n17    16\n14    16\n20    13\nName:  Industry sector, dtype: int64\n\nSummary statistics for Working Method:\n2    320\n3    173\n1    120\n4     76\nName: Working Method, dtype: int64\n\n\n2-Visualization: You can create visualizations to explore the relationship visually. For example, you can create a stacked bar chart to see how the distribution of Working Method varies across different Industry sectors. This can help you identify patterns or differences.\n\ncrosstab = pd.crosstab(data[' Industry sector'], data['Working Method'])\ncrosstab.plot(kind='bar', stacked=True)\n\n&lt;Axes: xlabel=' Industry sector'&gt;"
  },
  {
    "objectID": "posts/Classification/index.html",
    "href": "posts/Classification/index.html",
    "title": "Classificcation",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my posts",
    "section": "",
    "text": "quarto render\ngit push\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nProbability theory and random variables\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly-outlier detection DBSCAN labels for scatter plot\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nClassificcation\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nLinear and nonlinear regression\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nClustering\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "About.html",
    "href": "About.html",
    "title": "About!",
    "section": "",
    "text": "Hi,\nThis is Heba Nusair, a Ph.D. Candidate in Landscape Architecture at Virginia Tech. I am passionate about promoting sustainability and resilience in cities, with expertise in modeling urban growth planning using Geospatial Information Science. I have a broad background in land analysis and evaluation, urban planning, and design using GIS, honed through years of extensive experience in the field.\n\nMy current doctoral dissertation, ‘Predicting the Impact of Shifting to Work-from-Home Paradigm on Urban Sprawl Using Agent-Based Model and Artificial Intelligence,’ demonstrates my commitment to developing innovative solutions that address complex urban challenges on a large and medium city scale.\nI’m here to share my findings with you through a series of engaging blog posts. In some of these, I’ve even used synthesized data sets to shed light on different facets of the outcomes. So, whether you’re passionate about urban planning or just curious about the future of work, let’s dive into the world of the changing nature of work and urban development."
  },
  {
    "objectID": "posts/Anomaly-outlier detection DBSCAN labels for scatter plot/index.html",
    "href": "posts/Anomaly-outlier detection DBSCAN labels for scatter plot/index.html",
    "title": "Anomaly-outlier detection DBSCAN labels for scatter plot",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/Clustering/index.html",
    "href": "posts/Clustering/index.html",
    "title": "Clustering",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Linear and nonlinear regression/index.html",
    "href": "posts/Linear and nonlinear regression/index.html",
    "title": "Linear and nonlinear regression",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Research Insights Explorer Using Machine learning.html",
    "href": "Research Insights Explorer Using Machine learning.html",
    "title": "Research Insights Explorer Using Machine learning",
    "section": "",
    "text": "Important Note: The datasets used on these posts are modified and synthesized, so they should be used solely for educational purposes and to demonstrate data analysis techniques. Please refrain from using this data for any genuine applications.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbability theory and random variables\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly-outlier detection DBSCAN labels for scatter plot\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClassificcation\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear and nonlinear regression\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nClustering\n\n\n\nnews\n\n\ncode\n\n\nplot\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 3, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]