[
  {
    "objectID": "Research Overview.html",
    "href": "Research Overview.html",
    "title": "Research Overview",
    "section": "",
    "text": "Work From Home and Cityscape\nExperience the transformative shift in work dynamics worldwide. Fueled by factors like flexibility and propelled by the seismic impact of the Covid-19 pandemic, remote work, particularly Working From Home (WFH), has become a prevailing trend. This change in work culture is not merely a temporary response but a catalyst for a prolonged paradigm shift in workplaces globally.\nAs the emphasis on proximity to the workplace diminishes, individuals are opting for relocations to suburban areas, seeking affordable housing options without compromising living standards. This evolution in the work landscape intertwines with broader implications for cities—altering socioeconomic structures, reshaping urban landscapes, and influencing environmental dynamics.\n\nJoin us on this exploration of a dynamic era where work and living spaces converge, uncovering the profound effects of this transformative journey on cities, society, and the natural environment. Welcome to a new era in the world of work and living."
  },
  {
    "objectID": "posts/Probability theory and random variables/index.html",
    "href": "posts/Probability theory and random variables/index.html",
    "title": "Decoding Work Patterns, Analyzing Work From Home vs. Work On Site Trends in the 2023 US Job Market",
    "section": "",
    "text": "As we navigate through the evolving landscape of the 2023 job market, we are witnessing a significant shift in work methods. More people are embracing Work From Home (WFH) while others continue with Work On Site (WOS). This post helps to understand how these work methods vary across different jobs in the USA.\nMy Approach: For this analysis, I’ve utilized the Naive Bayes classifier for multivariate Bernoulli models. This method is excellent for sorting jobs into two main categories: WFH and WOS. It’s a practical choice for my study because it efficiently handles binary data—like choosing between remote or on-site work.\nAbout the Data: The data comes from a 2023 survey of 850 participants from various occupations. Participants were asked about their industry sector and working method. To respect data confidentiality, we’ve modified and anonymized the dataset. This ensures compliance with data privacy guidelines without affecting the overall analysis and insights.\n\n\n\nThe survey participants from workers and their working method (WFH, or WON).\n\n\nIndustry Breakdown: The study categorized 20 main category for jobs according to the North American Industry Classification System (NAICS), aligning with the 6-digit Standard Occupational Classification (SOC) system from the U.S. Bureau of Labor Statistics (BLS). Here’s a table of these industry sectors:\n\n\n\n\n\n\n\n\n#\nThe occupations categories are based on the 6-digit (SOC) system from the U.S. (BLS)\nIndustry Sector: Occupational Classification\n\n\n\n\n1\nNumber of jobs in NAICS sector 11\n(Agriculture, Forestry, Fishing and Hunting)\n\n\n2\ncns02 Number of jobs in NAICS sector 21\n(Mining, Quarrying, and Oil and Gas Extraction)\n\n\n3\ncns03 Number of jobs in NAICS sector 22\n(Utilities)\n\n\n4\ncns04 Number of jobs in NAICS sector 23\n(Construction)\n\n\n5\ncns05 Number of jobs in NAICS sector 31‐33\n(Manufacturing)\n\n\n6\ncns06 Number of jobs in NAICS sector 42\n(Wholesale Trade)\n\n\n7\ncns07 Number of jobs in NAICS sector 44‐45\n(Retail Trade)\n\n\n8\ncns08 Number of jobs in NAICS sector 48‐49\n(Transportation and Warehousing)\n\n\n9\ncns09 Number of jobs in NAICS sector 51\n(Information)\n\n\n10\ncns10 Number of jobs in NAICS sector 52\n(Finance and Insurance)\n\n\n11\ncns11 Number of jobs in NAICS sector 53\n(Real Estate and Rental and Leasing)\n\n\n12\ncns12 Number of jobs in NAICS sector 54\n(Professional, Scientific, and Technical Services)\n\n\n13\ncns13 Number of jobs in NAICS sector 55\n(Management of Companies and Enterprises)\n\n\n14\ncns14 Number of jobs in NAICS sector 56\n(Administrative and Support and Waste Management and Remediation Services)\n\n\n15\ncns15 Number of jobs in NAICS sector 61\n(Educational Services)\n\n\n16\ncns16 Number of jobs in NAICS sector 62\n(Health Care and Social Assistance)\n\n\n17\ncns17 Number of jobs in NAICS sector 71\n(Arts, Entertainment, and Recreation)\n\n\n18\ncns18 Number of jobs in NAICS sector 72\n(Accommodation and Food Services)\n\n\n19\ncns19 Number of jobs in NAICS sector 81\n(Other Services [except Public Administration])\n\n\n20\ncns20 Number of jobs in NAICS sector 92\n(Public Administration)\n\n\n\nGoal: My goal is to provide a clear and real picture of the changing work styles. I am not just analyzing numbers; I am uncovering the stories they tell about how people are adapting to new work environments, be it remotely or on-site.\nWhy I Chose the Naive Bayes Classifier for Multivariate Bernoulli Models:\nIn my exploration of work methods—remote and on-site—the Naive Bayes classifier for multivariate Bernoulli models shines with its simplicity and effectiveness. It excels at evaluating probabilities, helping determine whether a job is more likely to be remote or on-site based on its industry sector. This algorithm’s strength lies in its straightforward approach, providing clear baseline assessments that guide our analysis across different industry sectors. Dive Into the Code Behind the Analysis:\nx: The industry sector: [jobs categories From 1 to 20]\ny: The work method: 1 for WOS [Work on Site], 2 for WFH [Work From Home]\n\n\n\nCode\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\n\n# Load the dataset\ndf = pd.read_csv('C:/Users/NUSAI/Desktop/Machine learning/HebaNu.github.io/HebaNu.github.io/HebaNu/posts/Probability theory and random variables/updated_POST1.csv')\n\n# Drop rows where any cell is NaN in the 'Work Method' column\ndf = df.dropna(subset=['Work Method'])\n\n# One-hot encoding\nencoder = OneHotEncoder(sparse=False)\nX = encoder.fit_transform(df[[' industry sector']])  \n# includes 20 occupation types from NAICS for 6-digit SOC- U.S. BLS\n\n# Target variable\ny = df['Work Method']\n# 1 for WOS [Work on Site], 2 for WFH [Work From Home]\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the Bernoulli Naive Bayes model\nmodel = BernoulliNB()\nmodel.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\ny_pred = model.predict(X_test)\n\n\n\n# Output the classification report and accuracy\nprint(classification_report(y_test, y_pred, zero_division=0))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n\n\n              precision    recall  f1-score   support\n\n         1.0       0.00      0.00      0.00        40\n         2.0       0.76      1.00      0.87       130\n\n    accuracy                           0.76       170\n   macro avg       0.38      0.50      0.43       170\nweighted avg       0.58      0.76      0.66       170\n\nAccuracy: 0.7647058823529411\n\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning:\n\n`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n\n\n\nInsights from Our Model: Understanding the Work Trends\nThe results from our BernoulliNB model offer fascinating insights into the current work trends. The model is predicting class 2.0 for WFH [Work From Home] with high precision (76%) and recall (100%), which means for this class, it performs well both in terms of the accuracy of the positive predictions it makes (precision) and its ability to find all the positive instances (recall).\nFor class 1.0, however, the model does not predict any instances correctly, which suggests that either there’s an issue with the distribution of your classes (perhaps class 1.0 is underrepresented), or that the features do not provide enough information to distinguish class 1.0 from class 2.0. The overall accuracy of the model is 76.47%, which means that it correctly predicts the class for 76.47% of the test set.\nThe macro avg and weighted avg for precision, recall, and f1-score provide a summary of the effectiveness of the model across the classes. The low macro avg for precision and f1-score indicates that one of the classes does not perform well, which we already know is class 1.0.\nThe f1-score is a harmonic mean of precision and recall and is a useful metric when you have classes that are imbalanced. In my case, the f1-score for class 1.0 [WOS] is 0.00, indicating poor performance for this class.\nGenerally, the Naive Bayes classifier for multivariate Bernoulli models proves to be an effective and reliable tool for classification tasks. Its ability to handle binary data, like our work method categories, contributes to its robustness and applicability in various analytical scenarios.\nTo create plots that visualize the performance of your BernoulliNB model, you would typically look at the confusion matrix, precision-recall, and possibly ROC curves. Below are examples of how you could generate each of these plots using matplotlib and scikit-learn:\n\nConfusion Matrix: Visualizes the correct and incorrect predictions compared to the actual values.\n\n\n\nCode\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming y_test and y_pred are already defined from your BernoulliNB model\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion Matrix for BernoulliNB Model')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\n\n\n\n\nROC Curve: Plots the true positive rate against the false positive rate.\n\n\nCode\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\n\n# Adjust y_test to have binary labels 0 and 1\ny_test_binary = y_test.replace({1: 0, 2: 1})\n\n# Get predicted probabilities for the positive class (e.g., class 2)\ny_pred_prob = model.predict_proba(X_test)[:, 1]  # Index 1 for the probability of class 2\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_prob)\n\n# Calculate the AUC (Area Under Curve)\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve\ndisp = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\ndisp.plot()\nplt.title('ROC Curve for BernoulliNB Model')\nplt.show()\n\n\n\n\n\nClassification Report: Presents precision, recall, f1-score for each class.\n\n\nCode\nfrom sklearn.metrics import classification_report\nimport pandas as pd\n\nreport = classification_report(y_test, y_pred, output_dict=True)\ndf_report = pd.DataFrame(report).transpose()\n\ndf_report.drop(['accuracy'], inplace=True)  # Drop accuracy as it's not a class-specific metric\ndf_report.plot(kind='bar', figsize=(10, 7))\nplt.title('Classification Report for BernoulliNB Model')\nplt.ylabel('Score')\nplt.show()\n\n\n\n\n\nPlease note that in order to generate a ROC curve or Precision-Recall curve, you need the probability scores or decision function, not just the predicted labels. If y_pred contains only class labels, you would need to use the predict_proba or decision_function method of your classifier to obtain these scores.\nThese code snippets are intended to be run in your local Python environment, and you’ll need to ensure that y_test and y_pred are defined in your workspace after running your BernoulliNB model. If you encounter any issues with these plots or if you require further customization, feel free to ask for additional guidance.\nConclusions: Through our analysis, we aim to provide a clear picture of the current job market and its evolving nature. Whether it’s adapting to remote work setups or understanding the necessity of on-site roles, our study sheds light on these important trends.\nFinal Thoughts: As the world of work continues to change, we’re here to keep you informed and help you understand these shifts. Stay tuned for more insights and analyses on the changing job landscape!"
  },
  {
    "objectID": "posts/Exploratory Data Analysis (EDA)/index.html",
    "href": "posts/Exploratory Data Analysis (EDA)/index.html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Datasets Used in Our Analysis\nSurvey Overview:\nOur analysis is based on datasets primarily sourced from a survey conducted in 2023. This survey, designed and executed by our research team, targeted participants from a wide range of occupations across the USA. Its focus was on examining the significant impact of remote work on urban development and residential choices. The participants provided their insights through a detailed questionnaire, which covered aspects such as working methods (remote or in-person) and their effects on housing location preferences. This rich data offers insights into behavioral patterns related to working modes, thereby illuminating the interplay between human activity and urban spatial dynamics.\nData Modification for Privacy and Educational Use:\nIt’s important to note that the datasets featured in these blog posts have been modified and synthesized for educational purposes. They demonstrate various data analysis techniques but are not suitable for real-world applications due to these modifications. In compliance with data privacy guidelines, we have anonymized the dataset to maintain the confidentiality of the survey participants. However, these modifications do not detract from the overall integrity and analytical value of the data.\nPrimary Objective of the Dataset:\nThe main aim of this dataset is to explore the dynamics of the job market and their influence on urban landscapes. One of the key areas of inquiry in the survey was the industry sector and the preferred working method of the participants. By analyzing these elements, we gain a better understanding of current trends in the job market and how they shape urban environments.\nKey Elements of the Dataset:\nIn recent years, we’ve witnessed significant shifts in work methodologies. A growing number of professionals are embracing the Work From Home (WFH) approach, while a substantial segment continues to follow traditional Work On Site (WOS) practices. This study comprehensively covers 20 distinct industry sectors, focusing on four distinct categories of working methods. The details of these methods are outlined below:\n\n\n\n\n\n\n\n#\nWorking Method\n\n\n1\nFully remote (working from home or another location)\n\n\n2\nFully in-person (working at a physical office or location)\n\n\n3\nHybrid, dominated by in-person work (spending the majority of your work time at a physical office or location, with some remote work)\n\n\n4\nHybrid, dominated by remote work (spending the majority of your work time working from home or another location, with some in-person work)\n\n\n\nTwenty “industry sectors”or jobs are addressed based on the NAICS (North American Industry Classification System) to the 2-digit industry level. these jobs are as the following:\n\n\n\n\n\n\n\n\n\nThe number of industry sectors in NAICS\nDescription\n\n\n\n\n1\nsector 11\nAgriculture, Forestry, Fishing and Hunting\n\n\n2\nsector 21\nMining, Quarrying, and Oil and Gas Extraction\n\n\n3\nsector 22\nUtilities\n\n\n4\nsector 23\nConstruction\n\n\n5\nsector 31-33\nManufacturing\n\n\n6\nsector 42\nWholesale Trade\n\n\n7\nsector 44-45\nRetail Trade\n\n\n8\nsector 48-49\nTransportation and Warehousing\n\n\n9\nsector 51\nInformation\n\n\n10\nsector 52\nFinance and Insurance\n\n\n11\nsector 53\nReal Estate and Rental and Leasing\n\n\n12\nsector 54\nProfessional, Scientific, and Technical Services\n\n\n13\nsector 55\nManagement of Companies and Enterprises\n\n\n14\nsector 56\nAdministrative and Support and Waste Management and Remediation Services)\n\n\n15\nsector 61\nEducational Services\n\n\n16\nsector 62\nHealth Care and Social Assistance\n\n\n17\nsector 71\nArts, Entertainment, and Recreation\n\n\n18\nsector 72\nAccommodation and Food Services\n\n\n19\nsector 81\nOther Services (except Public Administration)\n\n\n20\nsector 92\nPublic Administration (not covered in economic census)\n\n\n\nEssentially, we want to see if the way people work is related to the industry they work in., Chi-Square Test of Independence is used to determine whether there is an association (relationship) between two categorical variables.\nIn our analysis, we’re testing two ideas:\n\nThe null hypothesis (H0): There’s no link between an employee’s industry sector and their working method. They’re independent of each other.\nThe alternative hypothesis (Ha): There is a significant link between the industry sector and the working method of employees.\n\n\n\nCode\n# Load necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency\n\n# Load your dataset without specifying encoding\ndata = pd.read_excel('Industry sector and working method.xlsx')\n\n# Summary statistics for Industry sector\nindustry_stats = data[' Industry sector'].value_counts()\n\n# Summary statistics for Working Method\nmethod_stats = data['Working Method'].value_counts()\n\n# Custom labels for Working Method, with line breaks\nworking_method_labels = [\n    'Fully remote\\n(working from home or another location)',\n    'Fully in-person\\n(working at a physical office or location)',\n    'Hybrid, dominated by\\nin-person work',\n    'Hybrid, dominated by\\nremote work'\n]\n\n# Plotting with adjusted figure size and subplot parameters\nplt.figure(figsize=(14, 8))  # Further increase the figure size\n\n# Industry Sector plot\nplt.subplot(1, 2, 1)\nsns.countplot(data=data, x=' Industry sector')\nplt.title('Distribution of Industry Sectors')\n\n\n# Plotting with horizontal bar chart\nplt.figure(figsize=(6, 5))  # Adjust figure size for horizontal plot\n\n# Working Method plot (horizontal)\nsns.countplot(data=data, y='Working Method')\nplt.title('Distribution of Working Methods')\nplt.yticks(range(len(working_method_labels)), working_method_labels)  # Set y-axis labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAlos, this plot is designed to visually explore the relationship between the industry sectors of employees and their working methods. It illustrates how the distribution of working methods varies across different industry sectors, allowing us to identify notable patterns or differences. Such visualizations are crucial for understanding the dynamics of the job market, particularly in the context of evolving work methodologies.\n\n\nCode\ncrosstab = pd.crosstab(data[' Industry sector'], data['Working Method'])\ncrosstab.plot(kind='bar', stacked=True)\n\n\n&lt;Axes: xlabel=' Industry sector'&gt;\n\n\n\n\n\nAdditionally, the dataset contains several key elements that will be crucial for our upcoming statistical analyses. The most important elements include:\n\n\n\nELement #\nDescription\nData Type\n\n\n1\nUnique identifier for each response\nNumerical\n\n\n2\nAbbreviation for country names\nCategorical\n\n\n3\nState or region within the country\nCategorical\n\n\n4\nGender identity of the respondent\nCategorical\n\n\n5\nAge range or specific age\nOrdinal\n\n\n6\nMarital status of the respondent\nCategorical\n\n\n7\nRace identification of the respondent\nCategorical\n\n\n8\nHighest level of education achieved\nOrdinal\n\n\n9\nNumber of days working in person\nNumerical\n\n\n10\nSpecific city or county of residence\nCategorical\n\n\n11\nSpecific city or county of work\nCategorical\n\n\n12\nAge of the company\nNumerical\n\n\n13\nNumber of employees or workers\nNumerical\n\n\n14\nDistance to work\nNumerical\n\n\n15\nHousing status\nCategorical\n\n\n16\nNumber of employed household members\nNumerical\n\n\n17\nHousehold size\nNumerical\n\n\n18\nDesired family size\nNumerical\n\n\n19\nIncome amount\nNumerical\n\n\n20\nSector of employment\nCategorical\n\n\n21\nPosition held at work\nTextual\n\n\n22\nWeekly working hours\nNumerical\n\n\n23\nWork mode (e.g., remote, in-person\nCategorical\n\n\n24\nImportance of physical interaction\nOrdinal\n\n\n25\nMode of transportation\nCategorical"
  },
  {
    "objectID": "posts/Clustering/index.html",
    "href": "posts/Clustering/index.html",
    "title": "Clustering",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.\n\n\nCode\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\n# Load the data\ndf = pd.read_csv('xy2.csv')\n\n# Assuming you're using 3 clusters (adjust as necessary)\nkmeans = KMeans(n_clusters=3, random_state=0)\nkmeans.fit(df[['X', 'Y']])\n\n# Assign the cluster labels to the DataFrame\ndf['Cluster'] = kmeans.labels_\n\n# Plotting the clusters\nplt.scatter(df['X'], df['Y'], c=df['Cluster'], cmap='viridis')\nplt.title('K-Means Clustering of Home Locations')\nplt.xlabel('X (Longitude)')\nplt.ylabel('Y (Latitude)')\nplt.colorbar(label='Cluster Label')\nplt.show()\n\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning:\n\nThe default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning"
  },
  {
    "objectID": "posts/Anomaly-outlier detection DBSCAN labels for scatter plot/index.html",
    "href": "posts/Anomaly-outlier detection DBSCAN labels for scatter plot/index.html",
    "title": "Anomaly-outlier detection DBSCAN labels for scatter plot",
    "section": "",
    "text": "This is a post with executable code.\n\n\nCode\n1 + 1\n\n\n[1] 2"
  },
  {
    "objectID": "About.html",
    "href": "About.html",
    "title": "About!",
    "section": "",
    "text": "Hi,\nThis is Heba Nusair, a Ph.D. Candidate in Landscape Architecture at Virginia Tech. I am passionate about promoting sustainability and resilience in cities, with expertise in modeling urban growth planning using Geospatial Information Science. I have a broad background in land analysis and evaluation, urban planning, and design using GIS, honed through years of extensive experience in the field.\n\nMy current doctoral dissertation, ‘Predicting the Impact of Shifting to Work-from-Home Paradigm on Urban Sprawl Using Agent-Based Model and Artificial Intelligence,’ demonstrates my commitment to developing innovative solutions that address complex urban challenges on a large and medium city scale.\nI’m here to share my findings with you through a series of engaging blog posts. In some of these, I’ve even used synthesized data sets to shed light on different facets of the outcomes. So, whether you’re passionate about urban planning or just curious about the future of work, let’s dive into the world of the changing nature of work and urban development."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my posts",
    "section": "",
    "text": "Code\nquarto render\ngit push\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nEDA 2\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nDecoding Work Patterns, Analyzing Work From Home vs. Work On Site Trends in the 2023 US Job Market\n\n\nProbability theory and random variables, Naive Bayes classifier for multivariate Bernoulli models\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly-outlier detection DBSCAN labels for scatter plot\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nUnveiling the Tapestry of Urban Preferences for Workers On Site (WOS), A Data-Driven Glimpse into Roanoke’s Metropolitan Living Choices\n\n\nRandom Forest Classifier\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nExploring the Relationship Between Income and Living Location Preference\n\n\nA Comparative Analysis of Linear and Non-Linear Regression Models\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nClustering\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Classification/index.html",
    "href": "posts/Classification/index.html",
    "title": "Unveiling the Tapestry of Urban Preferences for Workers On Site (WOS), A Data-Driven Glimpse into Roanoke’s Metropolitan Living Choices",
    "section": "",
    "text": "Deciding where to live for Workers on-Site (WOS) is a big decision for everyone, and for the people of Roanoke, it’s no different. We all have our own checklist when it comes to choosing our neighborhoods – some of us want to be close to work, others are looking for good schools for the kids, and some might prioritize a big backyard over everything else.\n\n\n\nFactors that might influence the residential decision-making process for Workers on_Site\n\n\nTo get to the heart of what matters most to Roanoke’s residents, we turned to data. Using a detailed survey filled with personal insights from locals. the datasets featured in these blog posts have been modified and synthesized for educational purposes. They demonstrate various data analysis techniques. We analyzed a range of factors from work life to family plans, all to answer one question: What drives people's choices about where they live?\nArmed with Python, a popular programming language, and a machine learning tool called Random Forest, we dug into the data. Think of Random Forest as a detective that examines all the evidence (or data) and identifies the usual suspects (or factors) that play a role in workers’ home-place choices.\nThe goal of using a Random Forest Classifier is to identify the factors that influence the residential preferences of Workers on-Site (WOS) in the Roanoke Metropolitan Area. Here are the specific objectives Random Forest helps to achieve:\n\nFeature Importance: Random Forest can determine the relative importance of each factor (like distance to work, income level, family size) in predicting residential preferences. This insight can inform urban planning and real estate development.\nPredictive Modeling: It can predict an individual’s preferred living area based on the features in the dataset, which could be useful for personalized recommendations or targeted marketing for real estate.\nHandling Complexity: Random Forest is robust to complex interactions between features and can handle non-linear relationships without the need for transformation, making it well-suited for diverse and complex datasets.\nReducing Overfitting: Due to its ensemble nature (combining multiple decision trees), Random Forest is less prone to overfitting compared to individual decision trees, leading to more reliable predictions.\nVersatility: It can handle both categorical and numerical data, making it versatile for datasets that contain a mix of different types of variables as is often the case in survey data.\nUnderstanding Population Segments: By examining which features are most influential, stakeholders can understand different segments of the population better and tailor their services or policies accordingly.\n\nIn essence, Random Forest acts as a powerful analytical tool that turns a complex array of data points into actionable insights about what drives people’s choices on where to live.\nAfter some thorough data cleaning to make sure we were working with accurate information, we let the Random Forest algorithm get to work. It looked at various details about people’s lives, including how far they live from work, their family size, and their income.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Load the dataset\ndata = pd.read_excel('Classification (In_person_Workers).xlsx')\n\n# Replace non-breaking spaces in column names\ndata.columns = data.columns.str.replace('\\xa0', ' ', regex=True)\n\n# Correct any potential typos in column names\n# Ensure these column names exactly match those in your DataFrame\ndata.rename(columns={'living costs ': 'living costs'}, inplace=True)\n\n# Convert the first four columns into a single ordinal dependent variable\n# Ensure these column names exactly match those in the DataFrame\narea_columns = ['City Center (Central Business District)', 'Urban area', 'Suburban area', 'Rural Area']\n# For each row, it finds the column among the specified area_columns that has the minimum value \n# (which would be equivalent to the highest preference rank, assuming 1 is the most preferred and \n# larger numbers indicate lower preferences) and stores the name of this column (i.e., the living area \n# with the highest preference for that row) as the value in the new Preferred_Living_Location column.\n\ndata['Preferred_Living_Location'] = data[area_columns].idxmin(axis=1)\ndata.drop(columns=area_columns, inplace=True)\n\n# Handle missing values (NaNs) for both features and target variable\ndata.dropna(inplace=True)\n\n# Define the list of categorical and continuous features\n# Replace these with the actual column names from the DataFrame\ncategorical_features = ['marital status', 'race', 'education level', 'firm age', 'firm size', 'owner or renter',\n                        'number of workers in household', 'people in household', 'desired family size in future',\n                        'monthly earning', 'industry sector']  # categorical features \ncontinuous_features = ['distance from work to homeplace']  # continuous features here\n\n# Preprocessing pipeline\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), continuous_features),\n        ('cat', OneHotEncoder(), categorical_features)\n    ])\n\n# Preprocess the data\nX = preprocessor.fit_transform(data.drop('Preferred_Living_Location', axis=1))\ny = data['Preferred_Living_Location'].astype(str)  # Convert to string if categorical\n\n# Split the data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the Random Forest Classifier\nrf = RandomForestClassifier()\nrf.fit(X_train, y_train)\n\n# Get feature importances\nfeature_names = continuous_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\nimportances = rf.feature_importances_\nsorted_indices = np.argsort(importances)[::-1]\n\n# Display feature importances\nprint(\"Feature Importances:\")\nfor i in sorted_indices:\n    print(f'{feature_names[i]}: {importances[i]}')\n\n\nFeature Importances:\ndistance from work to homeplace: 0.09011235359551276\nfirm size_3.0: 0.02167504508628453\nfirm age_2.0: 0.021408873047786034\nmonthly earning_3.0: 0.021300374981779877\nmonthly earning_2.0: 0.021104791686565837\nfirm size_2.0: 0.02038107912688128\nfirm age_3.0: 0.020377672185918086\neducation level_2.0: 0.019561013195953273\nrace_1.0: 0.019160845985101583\nowner or renter_1.0: 0.018844688445501634\neducation level_5.0: 0.018743929585324837\nmarital status_2.0: 0.018732905100052072\nnumber of workers in household_1.0: 0.01864951171166948\ndesired family size in future_5.0: 0.018570765277333097\nmarital status_1.0: 0.0183554146397528\nowner or renter_2.0: 0.018027869381383396\nfirm age_5.0: 0.017849832995759533\ndesired family size in future_2.0: 0.017709778947114164\npeople in household_4.0: 0.017478550813315077\ndesired family size in future_4.0: 0.017108715601662005\nfirm age_4.0: 0.016789726724356288\npeople in household_5.0: 0.01632334099234769\nnumber of workers in household_2.0: 0.016315228925747823\ndesired family size in future_3.0: 0.01617330407211762\npeople in household_3.0: 0.01596151321993006\nmonthly earning_1.0: 0.015766641391166493\neducation level_6.0: 0.015469621796173305\nnumber of workers in household_3.0: 0.01444229789038982\nindustry sector_Wholesale Trade: 0.013968582336908847\npeople in household_2.0: 0.01377259278645549\nfirm size_5.0: 0.013767487384934402\nindustry sector_Retail Trade: 0.01358248572297112\ndesired family size in future_1.0: 0.013291628355221366\nfirm size_4.0: 0.013122940639644762\nindustry sector_Manufacturing: 0.013119516927665826\nindustry sector_Management of Companies and Enterprises: 0.012396793671151303\neducation level_3.0: 0.01231469892410354\nindustry sector_Mining, Quarrying, and Oil and Gas Extraction: 0.012111582920120987\nfirm size_1.0: 0.011913091014210377\nrace_3.0: 0.011609226312156712\neducation level_8.0: 0.011537026783190858\nindustry sector_Professional, Scientific, and Technical Services: 0.011199638021275337\nmonthly earning_4.0: 0.01052700759911541\nindustry sector_Educational Services: 0.010205036918991639\nrace_2.0: 0.010026805636023728\neducation level_7.0: 0.0098947679109884\nindustry sector_Accommodation and Food Services: 0.009840734458996685\nfirm age_1.0: 0.00948400494738133\npeople in household_1.0: 0.009419535216725582\nmarital status_3.0: 0.009228706207743796\nindustry sector_Construction: 0.009227194164520424\nrace_4.0: 0.009002694805664308\nindustry sector_Transportation and Warehousing: 0.008942336106934033\nrace_8.0: 0.008907848400038656\nindustry sector_Information: 0.008868402017550112\nmarital status_6.0: 0.008618361553154848\nrace_5.0: 0.008476644897984376\nindustry sector_Finance and Insurance: 0.008361883551020069\nrace_6.0: 0.008125868560967775\neducation level_4.0: 0.007667547913807791\nmarital status_5.0: 0.007660091743322922\nrace_7.0: 0.0074212789687077285\nindustry sector_Health Care and Social Assistance: 0.007080778976052004\nindustry sector_Other Services [except Public Administration: 0.006831959747994634\nmarital status_4.0: 0.006751730481612872\nindustry sector_Agriculture, Forestry, Fishing and Hunting: 0.006571556611527378\nindustry sector_Utilities: 0.006480906049060427\nindustry sector_Arts, Entertainment, and Recreation: 0.006359433082532256\neducation level_1.0: 0.006036337578909815\nindustry sector_Administrative and Support and Waste Management and Remediation Services: 0.004731402662589878\nindustry sector_Public Administration: 0.004650142781900239\nindustry sector_Real Estate and Rental and Leasing: 0.004496022245289562\n\n\n\n[General Interpretation:\n\nThe features with higher importance scores are more influential in determining the preferred living area. This doesn’t necessarily mean causation but indicates a stronger association.\nThe model suggests that practical considerations like distance to work, firm age, earnings, and household characteristics play a significant role in determining living area preferences.\n\n\nCaveats:\n\nThe Random Forest model treats the problem as a classification task and does not inherently account for the ordinal nature of the dependent variable.\nThe results should be interpreted as indicative rather than definitive. For more precise modeling of ordinal outcomes, specific ordinal regression models would be more appropriate.\n\n\nIn summary, the model’s output provides a useful guide to understanding which factors are most influential in determining living area preferences, with distance from work appearing as the most significant factor according to this model.]\n\nThe results were clear: For workers who commute to work; the distance from workplace to homeplace stood out as the number one factor. This wasn’t too surprising – after all, who wants to spend hours in traffic when they could be home relaxing? Income was also a key factor. It seems the more we earn, the more choices we have about where we live.\n\nBut it’s not all about money and travel time. The data also showed us that personal factors, like whether someone is married or planning for a big family, have a big say in the decision too.\nThis isn’t just interesting information. It’s valuable knowledge for city planners and developers. By understanding what’s important to residents, they can plan and build communities that better meet people’s needs and make Roanoke an even better place to live.\nSo next time you’re driving through Roanoke’s neighborhoods, remember that each home you see represents a decision made based on a unique mix of practical needs and personal dreams.\nA Visual Journey Through Roanoke’s Residential Decision Drivers\nIn our previous discussion, we delved into the factors that influence where WOS in Roanoke choose to live. We discovered that the daily commute and income levels are among the top considerations. But how do these factors stack up against each other? Let’s take a visual dive into the data.\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming 'importances', 'feature_names' are already defined as in the previous code\n# Sorting the feature importances\nsorted_indices = np.argsort(importances)[::-1]\nsorted_importances = importances[sorted_indices]\nsorted_features = [feature_names[i] for i in sorted_indices]\n\n# Selecting a number of top features to display (you can adjust this number)\nn_top_features = 20  # for example, top 20 features\n\n# Creating the plot\nplt.figure(figsize=(6.5, 6.5))\nsns.barplot(x=sorted_importances[:n_top_features], y=sorted_features[:n_top_features])\nplt.title('Significance of factors in residential decision-making process')\nplt.xlabel('Level of importance')\nplt.ylabel('Factors')\nplt.show()\n\n\n\n\n\nThe accompanying chart lays out the findings from our Random Forest analysis in a colorful display of bars, each representing a factor’s weight in the decision-making process. At a glance, the lengthier bars catch the eye—these are the heavy hitters of home location preferece.\nDominating the scene is ‘distance from work to homeplace,’ a beacon of red at the top, which resonates with anyone who’s ever been caught in the snarl of rush hour. This is followed closely by a cascade of oranges and yellows highlighting the importance of ‘monthly earnings’ across various brackets and the age and size of firms.\nAs we move down the chart, the colors shift to cooler greens and blues, representing factors like household size and marital status. These may not be the titans of the plot, but they still play a pivotal role in the collective narrative of where we live.\nWhat’s truly intriguing is the story this visual tells us—beyond numbers and models, it’s about real-life choices and priorities. For instance, the significance of ‘people in household_4.0’ and ‘education level_5.0’ (a bachelor’s degree) speaks to the aspirations and day-to-day realities that shape our sense of place.\nCity planners and housing developers, take note: this chart is more than just a pretty picture. It’s a roadmap to the hearts and minds of Roanoke’s residents, guiding the way to communities that not only house but also support and enrich their lives.\nAs we continue to shape Roanoke’s urban landscape, let’s keep these visual cues in mind, ensuring that every development, from high-rises to townhomes, aligns with the genuine preferences of those who will call them home. After all, understanding these preferences is the key to building not just houses but homes where life’s stories can unfold."
  },
  {
    "objectID": "posts/CopyOfExploratory Data Analysis (EDA)2/index.html",
    "href": "posts/CopyOfExploratory Data Analysis (EDA)2/index.html",
    "title": "EDA 2",
    "section": "",
    "text": "The study and the attained dataset mainly focus on exploring the dynamic of the job market and its impact on the urban cityscape. Recent years marked a notable transformation in work methodologies. Many professionals are adopting the Work From Home (WFH) model, while many still adhere to traditional Work On Site (WOS) practices. My study delves into 20 distinct industry sectors, examining four unique classes of working methods and styles, as detailed below:\n\n\n\n1\nWorking On-Site [WOS]\n\n\n2\nWork From Home [WFH]\n\n\n\nThe data comes from a 2023 survey of 850 participants from various occupations. Participants were asked about their industry sector and working method. To respect data confidentiality, we’ve modified and anonymized the dataset. This ensures compliance with data privacy guidelines without affecting the overall analysis and insights.\n\n\nCode\n# Load necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nStudy the relationship between nominal variables (Industry sector and Working Method)statistical analyses:\n1- Chi-Square Test of Independence: The Chi-Square test can be used to determine whether there is an association (relationship) between two categorical variables. In your case, you can use it to test if there is a relationship between Industry sector and Working Method. The null hypothesis (H0) is that the two variables are independent, and the alternative hypothesis (Ha) is that there is a significant association between them.\n\n\nCode\n# Load necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency\n\n\n2-Visualization: You can create visualizations to explore the relationship visually. For example, you can create a stacked bar chart to see how the distribution of Working Method varies across different Industry sectors. This can help you identify patterns or differences."
  },
  {
    "objectID": "posts/Linear and nonlinear regression/index.html",
    "href": "posts/Linear and nonlinear regression/index.html",
    "title": "Exploring the Relationship Between Income and Living Location Preference",
    "section": "",
    "text": "Introduction\nHave you ever wondered how your income might influence your choice of where to live? We delved into this question, focusing on Workers From Home (WFH), using the power of linear regression. This statistical method helps us link two crucial aspects of our lives: income and our preferred living areas within metropolitan spaces. (See the figure).\n\n\n\nThe urban areas classification in Roanoke Metropolitan Area produced by the author.\n\n\n\n\nThe Study at a Glance\nOur dataset included responses from individuals, detailing their income levels and their preferred living areas, ranging from the bustling city center to the tranquil rural landscapes. We analyzed responses detailing income levels and preferred living areas, from busy city centers to peaceful rural settings. Our unique “relocating index” helped us turn these preferences into measurable data. So again, the variables used are processed as the following:\n\nTransforming income into a continuous scale, assigning monetary values to income brackets.\nConverting living area preferences into a single, ordinal dependent variable ‘Living Location Preference: moving from urban to rural index’.\n\n\n\nInsights from Linear Regression Analysis\nEmploying linear regression to model the relationship between the two variables: income & Relocating index.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocationPrefrences.xlsx')\n\n# Handle NaN values\ndata.dropna(subset=['City_center', 'Urban_area', 'Suburban_area', 'Rural_area', 'Monthly_income'], inplace=True)\n\n# Convert the Location preferences into a single ordinal dependent variable\narea_to_number = {'City_center': 1, 'Urban_area': 2, 'Suburban_area': 3, 'Rural_area': 4}\ndata['living_Location_preference'] = data[['City_center', 'Urban_area', 'Suburban_area', 'Rural_area']].idxmin(axis=1).map(area_to_number)\n\n# Convert income to a continuous scale based on the provided income brackets\nincome_mapping = {1.0: 625, 2.0: 2292, 3.0: 5000, 4.0: 6666}\ndata['continuous_income'] = data['Monthly_income'].map(income_mapping)\n\n# Scale the income feature\nscaler = StandardScaler()\ndata['scaled_income'] = scaler.fit_transform(data[['continuous_income']])\n\n# Prepare the features and target variable for modeling\nX = data[['scaled_income']]\ny = data['living_Location_preference']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred = model.predict(X_test)\n\n# Evaluate the model's performance\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Output the performance metrics\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\n\n# Debugging the sizes of arrays\nprint(\"Sizes of arrays for plotting:\")\nprint(\"X_test['scaled_income']: \", len(X_test['scaled_income']))\nprint(\"y_test: \", len(y_test))\nprint(\"y_pred: \", len(y_pred))\n\n# Plotting\nplt.scatter(X_test['scaled_income'].values, y_test.values, color='black', label='Actual Data')\nplt.scatter(X_test['scaled_income'].values, y_pred, color='red', label='Predicted Data', alpha=0.5)\n\n# Optionally, create a more continuous line for predictions\nsorted_order = np.argsort(X_test['scaled_income'].values)\nplt.plot(X_test['scaled_income'].values[sorted_order], y_pred[sorted_order], color='blue', linewidth=2, label='Regression Line')\n\nplt.xlabel('Monthly income')\nplt.ylabel('Living Location Preference:Relocating index_From urban to rural')\nplt.title('Income vs Living Location Preference Linear Regression')\nplt.legend()\nplt.show()\n\n\nMean Squared Error: 1.2658068009077692\nR-squared: 0.006851215790502296\nSizes of arrays for plotting:\nX_test['scaled_income']:  162\ny_test:  162\ny_pred:  162\n\n\n\n\n\nIn this plot, the actual data points (black dots) showed significant deviation from the blue regression line (the model’s predictions). The red dots, representing the model’s predicted values, also varied widely from many actual data points, indicating a mismatch between the model’s predictions and the real data.\n\n\nUnveiling the Linear Regression Insights for WFH Workers\nOur linear regression model yielded the following insights:\n\nMean Squared Error (MSE): The model showed an MSE of 1.2658068009077692. This number, though not extremely high, indicates some discrepancies between the model’s predictions and the actual data.\nR-squared Value: We obtained an R-squared value of 0.006851215790502296. This low value suggests that our model might not be capturing the complete picture, especially in the context of WFH employees.\n\n\n\nTransitioning to Non-Linear Models\nThe visual and numerical analysis led us to consider that the relationship between income and living area preferences might not be linear. This prompted a shift towards exploring non-linear patterns, We Chose a Multinomial Logistic Regression!!!! for these key reasons:\n\nAppropriate for Ordinal Data: Our data on living location preferences is ordinal (ranging from city centers to rural areas). Ordinal regression accurately handles such data, unlike linear regression.\nCaptures Non-Linear Patterns: This model is better suited to reveal non-linear relationships between income and living location preferences, which our initial analysis suggested.\nEnhanced Predictive Accuracy: Ordinal regression aligns more closely with our real-world data, potentially offering improved accuracy in predictions.\n\n\n\nImplementing Multinomial Logistic Regression Analysis\nIn this analysis. the location preferences into a single variable suggests that the resulting data is ordinal in nature. Here’s why:\n\nThe values assigned (1 for ‘City_center’, 2 for ‘Urban_area’, 3 for ‘Suburban_area’, and 4 for ‘Rural_area’) imply an order or ranking.\nThe order seems to represent a gradient from the most urbanized area (‘City_center’) to the least (‘Rural_area’).\n\nGiven this structure, the variable ‘preference rank’ would be more appropriate for ordinal regression analysis since it reflects a clear order or hierarchy in the data.\n\n\nCode\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocation_GradientBoostingRegressor.xlsx')  \n# Update the path to your file\n\n# Combine the area preferences into a single ordinal variable\ndef get_preference_rank(row):\n    if row['City_center'] == 1:\n        return 1\n    elif row['Urban_area'] == 1:\n        return 2\n    elif row['Suburban_area'] == 1:\n        return 3\n    elif row['Rural_area'] == 1:\n        return 4\n\ndata['living_area_preference'] = data.apply(get_preference_rank, axis=1)\n\n# Prepare the features and the target variable\nX = data[['Monthly_income', 'Education_Level', 'House_owner_or_renter', 'number of employees in household']]\ny = data['living_area_preference']\n\n# Add a constant to the model (intercept)\nX = sm.add_constant(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the ordinal regression model\nmodel = sm.MNLogit(y_train, X_train)\nresult = model.fit()\n\n# Output the model summary\nprint(result.summary())\n\n\nOptimization terminated successfully.\n         Current function value: 1.336686\n         Iterations 5\n                            MNLogit Regression Results                            \n==================================================================================\nDep. Variable:     living_area_preference   No. Observations:                  680\nModel:                            MNLogit   Df Residuals:                      665\nMethod:                               MLE   Df Model:                           12\nDate:                    Wed, 29 Nov 2023   Pseudo R-squ.:                 0.03553\nTime:                            00:14:47   Log-Likelihood:                -908.95\nconverged:                           True   LL-Null:                       -942.43\nCovariance Type:                nonrobust   LLR p-value:                 1.174e-09\n====================================================================================================\n        living_area_preference=2       coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------\nconst                                2.5322      0.630      4.020      0.000       1.298       3.767\nMonthly_income                      -0.6509      0.124     -5.230      0.000      -0.895      -0.407\nEducation_Level                      0.0909      0.055      1.642      0.101      -0.018       0.199\nHouse_owner_or_renter               -0.6254      0.262     -2.388      0.017      -1.139      -0.112\nnumber of employees in household    -0.2076      0.160     -1.296      0.195      -0.522       0.106\n----------------------------------------------------------------------------------------------------\n        living_area_preference=3       coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------\nconst                                2.8972      0.633      4.575      0.000       1.656       4.138\nMonthly_income                      -0.7957      0.126     -6.294      0.000      -1.043      -0.548\nEducation_Level                      0.0914      0.056      1.626      0.104      -0.019       0.202\nHouse_owner_or_renter               -0.6095      0.264     -2.307      0.021      -1.127      -0.092\nnumber of employees in household    -0.2320      0.163     -1.426      0.154      -0.551       0.087\n----------------------------------------------------------------------------------------------------\n        living_area_preference=4       coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------\nconst                                0.9399      0.628      1.496      0.135      -0.292       2.171\nMonthly_income                      -0.5330      0.124     -4.314      0.000      -0.775      -0.291\nEducation_Level                      0.1038      0.055      1.893      0.058      -0.004       0.211\nHouse_owner_or_renter               -0.0429      0.241     -0.178      0.859      -0.516       0.430\nnumber of employees in household     0.0543      0.160      0.341      0.733      -0.258       0.367\n====================================================================================================\n\n\n\n\nThe Multinomial Logistic Regression analysis revealed some interesting insights about the relationship between various factors and living area preferences:\n\nModel Convergence and Fit: The model successfully converged after 5 iterations, indicating a reliable fit to the data. The Pseudo R-squared value of 0.03553, while modest, suggests that our model has some explanatory power, though other unaccounted factors might also play a significant role.\nSignificant Predictors:\n\nMonthly Income: This was a significant predictor across all living area preferences (2, 3, and 4). The negative coefficients (-0.6509, -0.7957, and -0.5330) indicate that as monthly income increases, the likelihood of preferring urban (2) or suburban (3) areas over rural (4) areas decreases.\nHouse Ownership Status: This variable also showed significance in influencing living area preference, with negative coefficients suggesting that those who own houses or are renters are less likely to prefer urban or suburban areas compared to rural ones.\n\nOther Factors:\n\nEducation Level: While the coefficients were positive, suggesting a higher likelihood of preferring urban or suburban areas with increased education level, the significance was marginal.\nNumber of Employees in Household: This factor did not show a strong influence on living area preference, as indicated by the higher p-values.\n\nCoefficient Interpretation: The coefficients for each predictor vary for different living area preferences, reflecting the complex nature of these relationships. For instance, the impact of monthly income is more pronounced in preferring suburban areas (living_area_preference=3) than in urban or rural areas.\n\nIn conclusion, our Multinomial Logistic Regression model sheds light on how factors like income and house ownership status significantly influence living area preferences among WFH workers. The nuanced differences in coefficients across different living areas underscore the complexity of these relationships."
  },
  {
    "objectID": "Research Insights Explorer Using Machine learning.html",
    "href": "Research Insights Explorer Using Machine learning.html",
    "title": "Research Insights Explorer Using Machine learning",
    "section": "",
    "text": "Important Note: The datasets used on these posts are modified and synthesized, so they should be used solely for educational purposes and to demonstrate data analysis techniques. Please refrain from using this data for any genuine applications.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nEDA 2\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecoding Work Patterns, Analyzing Work From Home vs. Work On Site Trends in the 2023 US Job Market\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\nplot\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 11, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly-outlier detection DBSCAN labels for scatter plot\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling the Tapestry of Urban Preferences for Workers On Site (WOS), A Data-Driven Glimpse into Roanoke’s Metropolitan Living Choices\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Relationship Between Income and Living Location Preference\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nClustering\n\n\n\nnews\n\n\ncode\n\n\nplot\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 3, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 3, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]