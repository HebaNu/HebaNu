[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my posts",
    "section": "",
    "text": "Code\nquarto render\ngit push\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nPredicting Work Trends with Naive Bayes: Remote or On-Site Across Industries\n\n\nProbability theory and random variables, Naive Bayes classifier for multivariate Bernoulli models\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\nplot\n\n\n\n\n\n\n\n\n\n\n\nNov 25, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nUnveiling the Tapestry of Urban Preferences for Workers On Site (WOS), A Data-Driven Glimpse into Roanoke’s Metropolitan Living Choices\n\n\nRandom Forest Classifier\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 20, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nExploring the Relationship Between Income and Living Location Preference\n\n\nA Comparative Analysis of Linear and Non-Linear Regression Models\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nAnomaly-outlier detection DBSCAN labels for scatter plot\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nGeographic Clustering: Uncovering the Urban Patterns of Human Settlement in Roanoke and Salem Cities\n\n\nEmploying K-Means to Map and Understand Residential Densities\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 6, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\n  \n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 3, 2023\n\n\nHeba Nusair\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Clustering/index.html",
    "href": "posts/Clustering/index.html",
    "title": "Geographic Clustering: Uncovering the Urban Patterns of Human Settlement in Roanoke and Salem Cities",
    "section": "",
    "text": "In the bustling urban landscapes and the serene outskirts of Roanoke and Salem cities, every homeplace tells a story. Geographic clustering, a powerful analytical tool, allows us to uncover these stories by revealing the invisible patterns of human settlement and organization within these spaces. This analysis goes beyond mere numbers and dots on a map; it provides us with the insight to understand how populations distribute themselves across regions and how this distribution may affect and be affected by socio-economic factors.\n\n\n\nA Tapestry of Settlement: Over 55,000 points represent workers’ homeplaces scattered across the Roanoke and Salem cities, Painting a vivid picture of the urban landscape. Each point is a nexus of life and activity, contributing to the rich pattern of local habitation.\n\n\nIn this exploration, we dive into the spatial heart of Roanoke and Salem, employing a data-driven approach to demystify the geographic distribution and density of home locations. By utilizing the K-Means clustering technique, we aim to transcend the traditional narratives of urban planning and offer a unique lens through which we can comprehend the dynamics of these cities.\nJoin me on this cartographic journey as we navigate through the coordinates, interpret the clusters, and stitch together the fabric of these communities, one cluster at a time.\nData Description:\nThis dataset, retrieved from the web-based mapping tool OnTheMap, reveals the intricate interplay between workers’ employment locations and their residences. Carefully processed through Geographic Information Systems (GIS), the data presents a detailed residential fabric of 55,494 workers’ homeplaces in Roanoke and Salem cities. Each data point is a precise coordinate, marking the longitude (X) and latitude (Y) of individual dwellings. Together, they form an urban mosaic that not only maps out dense habitational clusters but also embodies the vibrant core of these communities, inviting us to explore the complex narrative of local settlement patterns.\nMethodology:\n\nChoosing the Right Tool: We employed K-Means clustering, a method perfect for drawing virtual boundaries around homes that are close together. It’s like sketching out neighborhoods based on where people live.\nData Standardization: Before clustering, we standardized the home coordinates. This ensures that every home, regardless of its actual geographical position, is treated equally in our analysis.\nFocused Analysis: We consciously left out job types from our study. Why? To focus solely on where people live. This allowed us to paint a clear picture of the residential layouts in Roanoke and Salem, unclouded by other factors.\n\n\n\nCode\nimport pandas as pd\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n# Load the data\ndf = pd.read_csv('Homeplaces in Roanoke and Salem Cities.csv')\n\n# Select only the geographic coordinates\ndf_geo = df[['X', 'Y']]\n\n# Standardizing the features (important for K-Means)\nscaler = StandardScaler()\ndf_geo_scaled = scaler.fit_transform(df_geo)\n\n# KMeans clustering\nkmeans = KMeans(n_clusters=5, n_init=10)\nclusters = kmeans.fit_predict(df_geo_scaled)\n\n# Adding cluster labels to dataframe\ndf['Cluster'] = clusters\n\n# Plotting the clusters\nplt.figure(figsize=(10, 6))\nplt.scatter(df['X'], df['Y'], c=df['Cluster'], cmap='viridis', marker='o')\n\nplt.title('Geographic Distribution of Homeplaces in Roanoke and Salem Cities')\nplt.xlabel('Longitude')\nplt.ylabel('Latitude')\nplt.colorbar(label='Cluster Label')\nplt.show()\n\n\n\n\n\nWhat we get is a straightforward, unfiltered view of how communities in these cities are shaped – a true representation of the area’s residential dynamics.\nDissecting Roanoke and Salem’s Residential Layout\nIn the visual analysis that unfolded, we used a scatter plot to translate the K-Means clustering algorithm’s output into a vibrant map. The algorithm diligently partitioned the area into five distinct clusters, each represented by a unique color—ranging from deep purple to bright yellow. The resulting plot is a testament to the power of data-driven geographical analysis.\nUpon examining the plot, the clusters emerge as distinct groupings that correspond to different areas within Roanoke and Salem. Some clusters are tightly packed, indicating neighborhoods with high home density, while others are more spread out, suggesting less populated or more spacious living areas. The color coding not only adds visual appeal but also signifies the cluster each home belongs to, with the color bar on the right serving as a handy reference.\nA closer look at the distribution of these clusters may reveal insights into the urban planning and development patterns of the cities. For example, we might observe that certain colors (clusters) concentrate around city centers or major transport routes, suggesting a correlation between home location and accessibility. On the other hand, some clusters could be outlining the suburban and peri-urban spread, hinting at the expansion of the cities’ residential zones.\nThese observations provide a starting point for urban analysts, policymakers, and planners to dive deeper into the factors driving such settlement patterns, potentially influencing future development and infrastructure planning to better accommodate the needs of Roanoke and Salem’s growing population.\nDiscussion: Interpreting the Living Fabric of Roanoke and Salem\n\nReal-World Correspondence: The clusters delineate the urban (dense, central areas), suburban (less dense, outskirts), and rural (sparse, peripheral areas) zones, painting a picture of residential density and urban spread.\nInfluencing Factors:\n\nAmenities: Areas with more facilities, like schools and malls, could attract larger populations, leading to denser clusters.\nTransport Infrastructure: Homes near major roads or public transit lines often form noticeable clusters, suggesting a preference for connectivity.\nEconomic Dynamics: Housing affordability and job availability are likely to influence where people choose to live, affecting the cluster distribution.\n\nOverlap Insights:\n\nTransition Zones: Overlapping clusters may signal transitional areas where different urban zones meet and meld.\nGrowth Patterns: These overlaps could also highlight regions undergoing development, indicating a blend of old and new neighborhoods.\n\nPlanning Implications: Recognizing these patterns is crucial for urban development strategies, aiming to balance growth with the preservation of the cities’ unique identities.\n\nConclusion: Unveiling the Geospatial Heartbeat of Roanoke and Salem\n\n\nKey Findings: Our analysis revealed distinct clusters that reflect the nuanced interplay between Roanoke and Salem’s urban, suburban, and rural landscapes. The clustering patterns highlighted not just where people live, but also how they are likely to interact with their environment based on proximity to amenities and infrastructure.\nSignificance of Geographic Clustering: The power of geographic clustering lies in its ability to transform raw data into a narrative about population distribution and urban dynamics. It offers a bird’s-eye view of the area’s residential heartbeat, providing insights into the patterns of human settlement.\nImplications for Urban Development: This clustering analysis is more than an academic exercise; it’s a tool for change. Urban planners and policymakers can harness this knowledge to make informed decisions about where to develop next, how to allocate resources efficiently, and how to plan future infrastructure. For instance, denser clusters might need more public transit, parks, or schools, while sparser ones could be targeted for sustainable development to prevent urban sprawl.\nBroader Applications: Beyond urban planning, this analysis could inform emergency services on where to focus preparedness efforts, help businesses decide where to open new locations, and guide environmental assessments to ensure green spaces are preserved and expanded.\n\n\nIn essence, by shedding light on how our cities pulse with life, geographic clustering empowers us to craft communities that are not only vibrant and prosperous but also equitable and sustainable."
  },
  {
    "objectID": "Research Insights Explorer Using Machine learning.html",
    "href": "Research Insights Explorer Using Machine learning.html",
    "title": "Research Insights Explorer Using Machine learning",
    "section": "",
    "text": "Important Note: The datasets used on these posts are modified and synthesized, so they should be used solely for educational purposes and to demonstrate data analysis techniques. Please refrain from using this data for any genuine applications.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPredicting Work Trends with Naive Bayes: Remote or On-Site Across Industries\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\nplot\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 25, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling the Tapestry of Urban Preferences for Workers On Site (WOS), A Data-Driven Glimpse into Roanoke’s Metropolitan Living Choices\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploring the Relationship Between Income and Living Location Preference\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 10, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnomaly-outlier detection DBSCAN labels for scatter plot\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeographic Clustering: Uncovering the Urban Patterns of Human Settlement in Roanoke and Salem Cities\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 6, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis (EDA)\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\nHeba Nusair\n\n\nNov 3, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Linear and nonlinear regression/index.html",
    "href": "posts/Linear and nonlinear regression/index.html",
    "title": "Exploring the Relationship Between Income and Living Location Preference",
    "section": "",
    "text": "Introduction\nLiving in Roanoke: Does Your Income Decide Your Address? We’ve dived into the world of Roanoke’s remote workers to see how much their earnings influence where they live. Using linear regression, we’ve connected the dots between income and neighborhood choices in this vibrant metropolitan area. Check out our eye-opening findings in the figure below! (See the figure).\n\n\n\nThe urban areas classification in Roanoke Metropolitan Area produced by the author.\n\n\n\n\nThe Study at a Glance\nOur dataset included responses from individuals, detailing their income levels and their preferred living areas, ranging from the bustling city center to the tranquil rural landscapes. We analyzed responses detailing income levels and preferred living areas, from busy city centers to peaceful rural settings. Our unique “relocating index” helped us turn these preferences into measurable data. So again, the variables used are processed as the following:\n\nTransforming income into a continuous scale, assigning monetary values to income brackets.\nConverting living area preferences into a single, ordinal dependent variable ‘Living Location Preference: moving from urban to rural index’.\n\n\n\nInsights from Linear Regression Analysis\nEmploying linear regression to model the relationship between the two variables: income & Relocating index.\n\n\nCode\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib.pyplot as plt\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocationPrefrences.xlsx')\n\n# Handle NaN values\ndata.dropna(subset=['City_center', 'Urban_area', 'Suburban_area', 'Rural_area', 'Monthly_income'], inplace=True)\n\n# Convert the Location preferences into a single ordinal dependent variable\narea_to_number = {'City_center': 1, 'Urban_area': 2, 'Suburban_area': 3, 'Rural_area': 4}\ndata['living_Location_preference'] = data[['City_center', 'Urban_area', 'Suburban_area', 'Rural_area']].idxmin(axis=1).map(area_to_number)\n\n# Convert income to a continuous scale based on the provided income brackets\nincome_mapping = {1.0: 625, 2.0: 2292, 3.0: 5000, 4.0: 6666}\ndata['continuous_income'] = data['Monthly_income'].map(income_mapping)\n\n# Scale the income feature\nscaler = StandardScaler()\ndata['scaled_income'] = scaler.fit_transform(data[['continuous_income']])\n\n# Prepare the features and target variable for modeling\nX = data[['scaled_income']]\ny = data['living_Location_preference']\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create and train the linear regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Predict on the test data\ny_pred = model.predict(X_test)\n\n# Evaluate the model's performance\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Output the performance metrics\nprint(f'Mean Squared Error: {mse}')\nprint(f'R-squared: {r2}')\n\n# Debugging the sizes of arrays\nprint(\"Sizes of arrays for plotting:\")\nprint(\"X_test['scaled_income']: \", len(X_test['scaled_income']))\nprint(\"y_test: \", len(y_test))\nprint(\"y_pred: \", len(y_pred))\n\n# Plotting\nplt.scatter(X_test['scaled_income'].values, y_test.values, color='black', label='Actual Data')\nplt.scatter(X_test['scaled_income'].values, y_pred, color='red', label='Predicted Data', alpha=0.5)\n\n# Optionally, create a more continuous line for predictions\nsorted_order = np.argsort(X_test['scaled_income'].values)\nplt.plot(X_test['scaled_income'].values[sorted_order], y_pred[sorted_order], color='blue', linewidth=2, label='Regression Line')\n\nplt.xlabel('Monthly income')\nplt.ylabel('Living Location Preference:Relocating index_From urban to rural')\nplt.title('Income vs Living Location Preference Linear Regression')\nplt.legend()\nplt.show()\n\n\nMean Squared Error: 1.2658068009077692\nR-squared: 0.006851215790502296\nSizes of arrays for plotting:\nX_test['scaled_income']:  162\ny_test:  162\ny_pred:  162\n\n\n\n\n\nIn this plot, the actual data points (black dots) showed significant deviation from the blue regression line (the model’s predictions). The red dots, representing the model’s predicted values, also varied widely from many actual data points, indicating a mismatch between the model’s predictions and the real data.\n\n\nUnveiling the Linear Regression Insights for WFH Workers\nOur linear regression model yielded the following insights:\n\nMean Squared Error (MSE): The model showed an MSE of 1.2658068009077692. This number, though not extremely high, indicates some discrepancies between the model’s predictions and the actual data.\nR-squared Value: We obtained an R-squared value of 0.006851215790502296. This low value suggests that our model might not be capturing the complete picture, especially in the context of WFH employees.\n\n\n\nTransitioning to Non-Linear Models\nThe visual and numerical analysis led us to consider that the relationship between income and living area preferences might not be linear. This prompted a shift towards exploring non-linear patterns, We Chose a Multinomial Logistic Regression!!!! for these key reasons:\n\nAppropriate for Ordinal Data: Our data on living location preferences is ordinal (ranging from city centers to rural areas). Ordinal regression accurately handles such data, unlike linear regression.\nCaptures Non-Linear Patterns: This model is better suited to reveal non-linear relationships between income and living location preferences, which our initial analysis suggested.\nEnhanced Predictive Accuracy: Ordinal regression aligns more closely with our real-world data, potentially offering improved accuracy in predictions.\n\n\n\nImplementing Multinomial Logistic Regression Analysis\nIn this analysis. the location preferences into a single variable suggests that the resulting data is ordinal in nature. Here’s why:\n\nThe values assigned (1 for ‘City_center’, 2 for ‘Urban_area’, 3 for ‘Suburban_area’, and 4 for ‘Rural_area’) imply an order or ranking.\nThe order seems to represent a gradient from the most urbanized area (‘City_center’) to the least (‘Rural_area’).\n\nGiven this structure, the variable ‘preference rank’ would be more appropriate for ordinal regression analysis since it reflects a clear order or hierarchy in the data.\n\n\nCode\nimport pandas as pd\nimport statsmodels.api as sm\nfrom sklearn.model_selection import train_test_split\n\n# Load the dataset\ndata = pd.read_excel('Income_LivingLocation_GradientBoostingRegressor.xlsx')  \n# Update the path to your file\n\n# Combine the area preferences into a single ordinal variable\ndef get_preference_rank(row):\n    if row['City_center'] == 1:\n        return 1\n    elif row['Urban_area'] == 1:\n        return 2\n    elif row['Suburban_area'] == 1:\n        return 3\n    elif row['Rural_area'] == 1:\n        return 4\n\ndata['living_area_preference'] = data.apply(get_preference_rank, axis=1)\n\n# Prepare the features and the target variable\nX = data[['Monthly_income', 'Education_Level', 'House_owner_or_renter', 'number of employees in household']]\ny = data['living_area_preference']\n\n# Add a constant to the model (intercept)\nX = sm.add_constant(X)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Fit the ordinal regression model\nmodel = sm.MNLogit(y_train, X_train)\nresult = model.fit()\n\n# Output the model summary\nprint(result.summary())\n\n\nOptimization terminated successfully.\n         Current function value: 1.336686\n         Iterations 5\n                            MNLogit Regression Results                            \n==================================================================================\nDep. Variable:     living_area_preference   No. Observations:                  680\nModel:                            MNLogit   Df Residuals:                      665\nMethod:                               MLE   Df Model:                           12\nDate:                    Wed, 29 Nov 2023   Pseudo R-squ.:                 0.03553\nTime:                            06:11:22   Log-Likelihood:                -908.95\nconverged:                           True   LL-Null:                       -942.43\nCovariance Type:                nonrobust   LLR p-value:                 1.174e-09\n====================================================================================================\n        living_area_preference=2       coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------\nconst                                2.5322      0.630      4.020      0.000       1.298       3.767\nMonthly_income                      -0.6509      0.124     -5.230      0.000      -0.895      -0.407\nEducation_Level                      0.0909      0.055      1.642      0.101      -0.018       0.199\nHouse_owner_or_renter               -0.6254      0.262     -2.388      0.017      -1.139      -0.112\nnumber of employees in household    -0.2076      0.160     -1.296      0.195      -0.522       0.106\n----------------------------------------------------------------------------------------------------\n        living_area_preference=3       coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------\nconst                                2.8972      0.633      4.575      0.000       1.656       4.138\nMonthly_income                      -0.7957      0.126     -6.294      0.000      -1.043      -0.548\nEducation_Level                      0.0914      0.056      1.626      0.104      -0.019       0.202\nHouse_owner_or_renter               -0.6095      0.264     -2.307      0.021      -1.127      -0.092\nnumber of employees in household    -0.2320      0.163     -1.426      0.154      -0.551       0.087\n----------------------------------------------------------------------------------------------------\n        living_area_preference=4       coef    std err          z      P&gt;|z|      [0.025      0.975]\n----------------------------------------------------------------------------------------------------\nconst                                0.9399      0.628      1.496      0.135      -0.292       2.171\nMonthly_income                      -0.5330      0.124     -4.314      0.000      -0.775      -0.291\nEducation_Level                      0.1038      0.055      1.893      0.058      -0.004       0.211\nHouse_owner_or_renter               -0.0429      0.241     -0.178      0.859      -0.516       0.430\nnumber of employees in household     0.0543      0.160      0.341      0.733      -0.258       0.367\n====================================================================================================\n\n\n\n\nThe Multinomial Logistic Regression analysis revealed some interesting insights about the relationship between various factors and living area preferences:\n\nModel Convergence and Fit: The model successfully converged after 5 iterations, indicating a reliable fit to the data. The Pseudo R-squared value of 0.03553, while modest, suggests that our model has some explanatory power, though other unaccounted factors might also play a significant role.\nSignificant Predictors:\n\nMonthly Income: This was a significant predictor across all living area preferences (2, 3, and 4). The negative coefficients (-0.6509, -0.7957, and -0.5330) indicate that as monthly income increases, the likelihood of preferring urban (2) or suburban (3) areas over rural (4) areas decreases.\nHouse Ownership Status: This variable also showed significance in influencing living area preference, with negative coefficients suggesting that those who own houses or are renters are less likely to prefer urban or suburban areas compared to rural ones.\n\nOther Factors:\n\nEducation Level: While the coefficients were positive, suggesting a higher likelihood of preferring urban or suburban areas with increased education level, the significance was marginal.\nNumber of Employees in Household: This factor did not show a strong influence on living area preference, as indicated by the higher p-values.\n\nCoefficient Interpretation: The coefficients for each predictor vary for different living area preferences, reflecting the complex nature of these relationships. For instance, the impact of monthly income is more pronounced in preferring suburban areas (living_area_preference=3) than in urban or rural areas.\n\nIn conclusion, our Multinomial Logistic Regression model sheds light on how factors like income and house ownership status significantly influence living area preferences among WFH workers. The nuanced differences in coefficients across different living areas underscore the complexity of these relationships."
  },
  {
    "objectID": "posts/Exploratory Data Analysis (EDA)/index.html",
    "href": "posts/Exploratory Data Analysis (EDA)/index.html",
    "title": "Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Datasets Used in Our Analysis\nSurvey Overview:\nOur analysis is based on datasets primarily sourced from a survey conducted in 2023. This survey, designed and executed by our research team, targeted participants from a wide range of occupations across the USA. Its focus was on examining the significant impact of remote work on urban development and residential choices. The participants provided their insights through a detailed questionnaire, which covered aspects such as working methods (remote or in-person) and their effects on housing location preferences. This rich data offers insights into behavioral patterns related to working modes, thereby illuminating the interplay between human activity and urban spatial dynamics.\nData Modification for Privacy and Educational Use:\nIt’s important to note that the datasets featured in these blog posts have been modified and synthesized for educational purposes. They demonstrate various data analysis techniques but are not suitable for real-world applications due to these modifications. In compliance with data privacy guidelines, we have anonymized the dataset to maintain the confidentiality of the survey participants. However, these modifications do not detract from the overall integrity and analytical value of the data.\nPrimary Objective of the Dataset:\nThe main aim of this dataset is to explore the dynamics of the job market and their influence on urban landscapes. One of the key areas of inquiry in the survey was the industry sector and the preferred working method of the participants. By analyzing these elements, we gain a better understanding of current trends in the job market and how they shape urban environments.\nKey Elements of the Dataset:\nIn recent years, we’ve witnessed significant shifts in work methodologies. A growing number of professionals are embracing the Work From Home (WFH) approach, while a substantial segment continues to follow traditional Work On Site (WOS) practices. This study comprehensively covers 20 distinct industry sectors, focusing on four distinct categories of working methods. The details of these methods are outlined below:\n\n\n\n\n\n\n\n#\nWorking Method\n\n\n1\nFully remote (working from home or another location)\n\n\n2\nFully in-person (working at a physical office or location)\n\n\n3\nHybrid, dominated by in-person work (spending the majority of your work time at a physical office or location, with some remote work)\n\n\n4\nHybrid, dominated by remote work (spending the majority of your work time working from home or another location, with some in-person work)\n\n\n\nTwenty “industry sectors”or jobs are addressed based on the NAICS (North American Industry Classification System) to the 2-digit industry level. these jobs are as the following:\n\n\n\n\n\n\n\n\n\nThe number of industry sectors in NAICS\nDescription\n\n\n\n\n1\nsector 11\nAgriculture, Forestry, Fishing and Hunting\n\n\n2\nsector 21\nMining, Quarrying, and Oil and Gas Extraction\n\n\n3\nsector 22\nUtilities\n\n\n4\nsector 23\nConstruction\n\n\n5\nsector 31-33\nManufacturing\n\n\n6\nsector 42\nWholesale Trade\n\n\n7\nsector 44-45\nRetail Trade\n\n\n8\nsector 48-49\nTransportation and Warehousing\n\n\n9\nsector 51\nInformation\n\n\n10\nsector 52\nFinance and Insurance\n\n\n11\nsector 53\nReal Estate and Rental and Leasing\n\n\n12\nsector 54\nProfessional, Scientific, and Technical Services\n\n\n13\nsector 55\nManagement of Companies and Enterprises\n\n\n14\nsector 56\nAdministrative and Support and Waste Management and Remediation Services)\n\n\n15\nsector 61\nEducational Services\n\n\n16\nsector 62\nHealth Care and Social Assistance\n\n\n17\nsector 71\nArts, Entertainment, and Recreation\n\n\n18\nsector 72\nAccommodation and Food Services\n\n\n19\nsector 81\nOther Services (except Public Administration)\n\n\n20\nsector 92\nPublic Administration (not covered in economic census)\n\n\n\nEssentially, we want to see if the way people work is related to the industry they work in., Chi-Square Test of Independence is used to determine whether there is an association (relationship) between two categorical variables.\nIn our analysis, we’re testing two ideas:\n\nThe null hypothesis (H0): There’s no link between an employee’s industry sector and their working method. They’re independent of each other.\nThe alternative hypothesis (Ha): There is a significant link between the industry sector and the working method of employees.\n\n\n\nCode\n# Load necessary libraries\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import chi2_contingency\n\n# Load your dataset without specifying encoding\ndata = pd.read_excel('Industry sector and working method.xlsx')\n\n# Summary statistics for Industry sector\nindustry_stats = data[' Industry sector'].value_counts()\n\n# Summary statistics for Working Method\nmethod_stats = data['Working Method'].value_counts()\n\n# Custom labels for Working Method, with line breaks\nworking_method_labels = [\n    'Fully remote\\n(working from home or another location)',\n    'Fully in-person\\n(working at a physical office or location)',\n    'Hybrid, dominated by\\nin-person work',\n    'Hybrid, dominated by\\nremote work'\n]\n\n# Plotting with adjusted figure size and subplot parameters\nplt.figure(figsize=(14, 8))  # Further increase the figure size\n\n# Industry Sector plot\nplt.subplot(1, 2, 1)\nsns.countplot(data=data, x=' Industry sector')\nplt.title('Distribution of Industry Sectors')\n\n\n# Plotting with horizontal bar chart\nplt.figure(figsize=(6, 5))  # Adjust figure size for horizontal plot\n\n# Working Method plot (horizontal)\nsns.countplot(data=data, y='Working Method')\nplt.title('Distribution of Working Methods')\nplt.yticks(range(len(working_method_labels)), working_method_labels)  # Set y-axis labels\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAlos, this plot is designed to visually explore the relationship between the industry sectors of employees and their working methods. It illustrates how the distribution of working methods varies across different industry sectors, allowing us to identify notable patterns or differences. Such visualizations are crucial for understanding the dynamics of the job market, particularly in the context of evolving work methodologies.\n\n\nCode\ncrosstab = pd.crosstab(data[' Industry sector'], data['Working Method'])\ncrosstab.plot(kind='bar', stacked=True)\n\n\n&lt;Axes: xlabel=' Industry sector'&gt;\n\n\n\n\n\nAdditionally, the dataset contains several key elements that will be crucial for our upcoming statistical analyses. The most important elements include:\n\n\n\nELement #\nDescription\nData Type\n\n\n1\nUnique identifier for each response\nNumerical\n\n\n2\nAbbreviation for country names\nCategorical\n\n\n3\nState or region within the country\nCategorical\n\n\n4\nGender identity of the respondent\nCategorical\n\n\n5\nAge range or specific age\nOrdinal\n\n\n6\nMarital status of the respondent\nCategorical\n\n\n7\nRace identification of the respondent\nCategorical\n\n\n8\nHighest level of education achieved\nOrdinal\n\n\n9\nNumber of days working in person\nNumerical\n\n\n10\nSpecific city or county of residence\nCategorical\n\n\n11\nSpecific city or county of work\nCategorical\n\n\n12\nAge of the company\nNumerical\n\n\n13\nNumber of employees or workers\nNumerical\n\n\n14\nDistance to work\nNumerical\n\n\n15\nHousing status\nCategorical\n\n\n16\nNumber of employed household members\nNumerical\n\n\n17\nHousehold size\nNumerical\n\n\n18\nDesired family size\nNumerical\n\n\n19\nIncome amount\nNumerical\n\n\n20\nSector of employment\nCategorical\n\n\n21\nPosition held at work\nTextual\n\n\n22\nWeekly working hours\nNumerical\n\n\n23\nWork mode (e.g., remote, in-person\nCategorical\n\n\n24\nImportance of physical interaction\nOrdinal\n\n\n25\nMode of transportation\nCategorical"
  },
  {
    "objectID": "posts/Probability theory and random variables/index.html",
    "href": "posts/Probability theory and random variables/index.html",
    "title": "Predicting Work Trends with Naive Bayes: Remote or On-Site Across Industries",
    "section": "",
    "text": "As we navigate through the evolving landscape of the 2023 job market, we are witnessing a significant shift in work methods. More people are embracing Work From Home (WFH) while others continue with Work On Site (WOS). This post helps to understand how these work methods vary across different jobs in the USA.\nMy Approach: For this analysis, I’ve utilized the Naive Bayes classifier for multivariate Bernoulli models. This method is excellent for sorting jobs into two main categories: WFH and WOS. It’s a practical choice for my study because it efficiently handles binary data—like choosing between remote or on-site work.\nAbout the Data: The data comes from a 2023 survey of 850 participants from various occupations. Participants were asked about their industry sector and working method. To respect data confidentiality, we’ve modified and anonymized the dataset. This ensures compliance with data privacy guidelines without affecting the overall analysis and insights.\n\n\n\nThe survey participants from workers and their working method (WFH, or WON).\n\n\nIndustry Breakdown: The study categorized 20 main category for jobs according to the North American Industry Classification System (NAICS), aligning with the 6-digit Standard Occupational Classification (SOC) system from the U.S. Bureau of Labor Statistics (BLS). Here’s a table of these industry sectors:\n\n\n\n\n\n\n\n\n#\nThe occupations categories are based on the 6-digit (SOC) system from the U.S. (BLS)\nIndustry Sector: Occupational Classification\n\n\n\n\n1\nNumber of jobs in NAICS sector 11\n(Agriculture, Forestry, Fishing and Hunting)\n\n\n2\ncns02 Number of jobs in NAICS sector 21\n(Mining, Quarrying, and Oil and Gas Extraction)\n\n\n3\ncns03 Number of jobs in NAICS sector 22\n(Utilities)\n\n\n4\ncns04 Number of jobs in NAICS sector 23\n(Construction)\n\n\n5\ncns05 Number of jobs in NAICS sector 31‐33\n(Manufacturing)\n\n\n6\ncns06 Number of jobs in NAICS sector 42\n(Wholesale Trade)\n\n\n7\ncns07 Number of jobs in NAICS sector 44‐45\n(Retail Trade)\n\n\n8\ncns08 Number of jobs in NAICS sector 48‐49\n(Transportation and Warehousing)\n\n\n9\ncns09 Number of jobs in NAICS sector 51\n(Information)\n\n\n10\ncns10 Number of jobs in NAICS sector 52\n(Finance and Insurance)\n\n\n11\ncns11 Number of jobs in NAICS sector 53\n(Real Estate and Rental and Leasing)\n\n\n12\ncns12 Number of jobs in NAICS sector 54\n(Professional, Scientific, and Technical Services)\n\n\n13\ncns13 Number of jobs in NAICS sector 55\n(Management of Companies and Enterprises)\n\n\n14\ncns14 Number of jobs in NAICS sector 56\n(Administrative and Support and Waste Management and Remediation Services)\n\n\n15\ncns15 Number of jobs in NAICS sector 61\n(Educational Services)\n\n\n16\ncns16 Number of jobs in NAICS sector 62\n(Health Care and Social Assistance)\n\n\n17\ncns17 Number of jobs in NAICS sector 71\n(Arts, Entertainment, and Recreation)\n\n\n18\ncns18 Number of jobs in NAICS sector 72\n(Accommodation and Food Services)\n\n\n19\ncns19 Number of jobs in NAICS sector 81\n(Other Services [except Public Administration])\n\n\n20\ncns20 Number of jobs in NAICS sector 92\n(Public Administration)\n\n\n\nGoal: My goal is to provide a clear and real picture of the changing work styles. I am not just analyzing numbers; I am uncovering the stories they tell about how people are adapting to new work environments, be it remotely or on-site.\nWhy I Chose the Naive Bayes Classifier for Multivariate Bernoulli Models:\nIn my exploration of work methods—remote and on-site—the Naive Bayes classifier for multivariate Bernoulli models shines with its simplicity and effectiveness. It excels at evaluating probabilities, helping determine whether a job is more likely to be remote or on-site based on its industry sector. This algorithm’s strength lies in its straightforward approach, providing clear baseline assessments that guide our analysis across different industry sectors. Dive Into the Code Behind the Analysis:\nx: The industry sector: [jobs categories From 1 to 20]\ny: The work method: 1 for WOS [Work on Site], 2 for WFH [Work From Home]\n\n\n\nCode\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nimport os\n\n# Load the dataset\ndf = pd.read_csv('C:/Users/NUSAI/Desktop/Machine learning/HebaNu.github.io/HebaNu.github.io/HebaNu/posts/Probability theory and random variables/updated_POST1.csv')\n\n# Drop rows where any cell is NaN in the 'Work Method' column\ndf = df.dropna(subset=['Work Method'])\n\n# One-hot encoding\nencoder = OneHotEncoder(sparse=False)\nX = encoder.fit_transform(df[[' industry sector']])  \n# includes 20 occupation types from NAICS for 6-digit SOC- U.S. BLS\n\n# Target variable\ny = df['Work Method']\n# 1 for WOS [Work on Site], 2 for WFH [Work From Home]\n\n# Split the dataset\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the Bernoulli Naive Bayes model\nmodel = BernoulliNB()\nmodel.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\ny_pred = model.predict(X_test)\n\n\n\n# Output the classification report and accuracy\nprint(classification_report(y_test, y_pred, zero_division=0))\nprint(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n\n\n              precision    recall  f1-score   support\n\n         1.0       0.00      0.00      0.00        40\n         2.0       0.76      1.00      0.87       130\n\n    accuracy                           0.76       170\n   macro avg       0.38      0.50      0.43       170\nweighted avg       0.58      0.76      0.66       170\n\nAccuracy: 0.7647058823529411\n\n\nC:\\Users\\NUSAI\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning:\n\n`sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n\n\n\nInsights from Our Model: Understanding the Work Trends\nThe results from our BernoulliNB model offer fascinating insights into the current work trends. The model is predicting class 2.0 for WFH [Work From Home] with high precision (76%) and recall (100%), which means for this class, it performs well both in terms of the accuracy of the positive predictions it makes (precision) and its ability to find all the positive instances (recall).\nFor class 1.0, however, the model does not predict any instances correctly, which suggests that either there’s an issue with the distribution of your classes (perhaps class 1.0 is underrepresented), or that the features do not provide enough information to distinguish class 1.0 from class 2.0. The overall accuracy of the model is 76.47%, which means that it correctly predicts the class for 76.47% of the test set.\nThe macro avg and weighted avg for precision, recall, and f1-score provide a summary of the effectiveness of the model across the classes. The low macro avg for precision and f1-score indicates that one of the classes does not perform well, which we already know is class 1.0.\nThe f1-score is a harmonic mean of precision and recall and is a useful metric when you have classes that are imbalanced. In my case, the f1-score for class 1.0 [WOS] is 0.00, indicating poor performance for this class.\nGenerally, the Naive Bayes classifier for multivariate Bernoulli models proves to be an effective and reliable tool for classification tasks. Its ability to handle binary data, like our work method categories, contributes to its robustness and applicability in various analytical scenarios.\nTo create plots that visualize the performance of your BernoulliNB model, you would typically look at the confusion matrix, precision-recall, and possibly ROC curves. Below are examples of how you could generate each of these plots using matplotlib and scikit-learn:\n\nConfusion Matrix: Visualizes the correct and incorrect predictions compared to the actual values.\n\n\n\nCode\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Assuming y_test and y_pred are already defined from BernoulliNB model\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title('Confusion Matrix for BernoulliNB Model')\nplt.xlabel('Predicted Labels')\nplt.ylabel('True Labels')\nplt.show()\n\n\n\n\n\nROC Curve: Plots the true positive rate against the false positive rate.\n\n\nCode\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import RocCurveDisplay\nimport matplotlib.pyplot as plt\n\n# Adjust y_test to have binary labels 0 and 1\ny_test_binary = y_test.replace({1: 0, 2: 1})\n\n# Get predicted probabilities for the positive class (e.g., class 2)\ny_pred_prob = model.predict_proba(X_test)[:, 1]  # Index 1 for the probability of class 2\n\n# Calculate the ROC curve\nfpr, tpr, thresholds = roc_curve(y_test_binary, y_pred_prob)\n\n# Calculate the AUC (Area Under Curve)\nroc_auc = auc(fpr, tpr)\n\n# Plot the ROC curve\ndisp = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\ndisp.plot()\nplt.title('ROC Curve for BernoulliNB Model')\nplt.show()\n\n\n\n\n\nConclusions: Through our analysis, we aim to provide a clear picture of the current job market and its evolving nature. Whether it’s adapting to remote work setups or understanding the necessity of on-site roles, our study sheds light on these important trends.\nFinal Thoughts: As the world of work continues to change, we’re here to keep you informed and help you understand these shifts. Stay tuned for more insights and analyses on the changing job landscape!"
  },
  {
    "objectID": "Research Overview.html",
    "href": "Research Overview.html",
    "title": "Research Overview",
    "section": "",
    "text": "Work From Home and Cityscape\nExperience the transformative shift in work dynamics worldwide. Fueled by factors like flexibility and propelled by the seismic impact of the Covid-19 pandemic, remote work, particularly Working From Home (WFH), has become a prevailing trend. This change in work culture is not merely a temporary response but a catalyst for a prolonged paradigm shift in workplaces globally.\nAs the emphasis on proximity to the workplace diminishes, individuals are opting for relocations to suburban areas, seeking affordable housing options without compromising living standards. This evolution in the work landscape intertwines with broader implications for cities—altering socioeconomic structures, reshaping urban landscapes, and influencing environmental dynamics.\n\nJoin us on this exploration of a dynamic era where work and living spaces converge, uncovering the profound effects of this transformative journey on cities, society, and the natural environment. Welcome to a new era in the world of work and living."
  }
]